{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import maxout\n",
    "import highway_maxout as hmn\n",
    "import utils\n",
    "import dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======= FLAGS ==========\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('maxout_layer_size', 8, 'Maxout layer size')\n",
    "tf.app.flags.DEFINE_integer('maxout_pooling_size', 16, 'Maxout pooling size')\n",
    "tf.app.flags.DEFINE_integer('lstm_size', 10, 'LSTM cell internal size')\n",
    "tf.app.flags.DEFINE_string('log_path', '/tmp/dcn', 'logs location')\n",
    "tf.app.flags.DEFINE_integer('acc_batch_size', 10, 'How many examples to use to calculate accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all variables\n",
    "tf.reset_default_graph();\n",
    "\n",
    "lstm_size = FLAGS.lstm_size\n",
    "acc_batch_size = FLAGS.acc_batch_size\n",
    "word_vector_size = 300\n",
    "maxout_pooling_size = 16\n",
    "max_decoder_iterations = 4\n",
    "maxout_layer_size = FLAGS.maxout_layer_size;\n",
    "max_epoch = 1;\n",
    "max_sequence_length = 15\n",
    "#training_set_size = 100;\n",
    "\n",
    "# \n",
    "question_ph = tf.placeholder(tf.float32, [1, max_sequence_length, word_vector_size], name=\"q_input\")\n",
    "document_ph = tf.placeholder(tf.float32, [1, max_sequence_length, word_vector_size], name=\"d_input\")\n",
    "\n",
    "\n",
    "with tf.name_scope('ENCODER'):\n",
    "    # LSTM cell initialization\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "\n",
    "\n",
    "# LSTM cells for Bi-LSTM for COATINATION ENCODER\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    lstm_cenc_fw = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    lstm_cenc_bw = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "\n",
    "# create lstm cell for DYNAMIC POINTING DECODER\n",
    "lstm_dec = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# get lstm initial state of zeroes\n",
    "#lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "start_pos = 0; # generate random between (0, document_size-1)\n",
    "end_pos = 0;   # generate random between (0, document_size-1)\n",
    "\n",
    "# create sentinel vector variable for both encodings \n",
    "#with tf.variable_scope(\"scope1\") as scope:\n",
    "sentinel_q = tf.get_variable(\"sentinel_q\", [ lstm_size , 1], initializer = tf.random_normal_initializer())\n",
    "sentinel_d = tf.get_variable(\"sentinel_d\", [ lstm_size , 1], initializer = tf.random_normal_initializer()) \n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"COATTENTION_ENCODER_2/strided_slice:0\", shape=(16, 20), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'U:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# r = lstm(inputs = tf.convert_to_tensor([[1,2], [2,3]], dtype=tf.float32), state = zero_state_q)\n",
    "\n",
    "def length(sequence):\n",
    "  used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "  length = tf.reduce_sum(used, 1)\n",
    "  length = tf.cast(length, tf.int32)\n",
    "  return length\n",
    "\n",
    "'''\n",
    "transform tensor of shape [1, question_size, word_vector_size] to list of tensors of shape [1, word_vector_size]\n",
    "of length question_size. first dimenstion is batch size = 1\n",
    "'''\n",
    "\n",
    "#print(tf.shape(question_ph)[1])\n",
    "#question_input = tf.unstack(question_ph, max_sequence_length, 1)\n",
    "#document_input = tf.unstack(document_ph, max_sequence_length, 1)\n",
    "#print(x)\n",
    "\n",
    "# we use the same LSTM for both encodings to share weights\n",
    "with tf.name_scope('ENCODER'):\n",
    "    with tf.name_scope('Q_ENC'):\n",
    "        outputs_q, state_q = tf.nn.dynamic_rnn(lstm, inputs = question_ph, sequence_length = length(question_ph), dtype=tf.float32)\n",
    "    with tf.name_scope('D_ENC'):\n",
    "        outputs_d, state_d = tf.nn.dynamic_rnn(lstm, inputs = document_ph, sequence_length = length(document_ph), dtype=tf.float32)\n",
    "\n",
    "\n",
    "# \"squeeze\" transforms list of tensors of shape [1, lstm_size] of length L to tensor of shape [L, lstm_size]\n",
    "que_enc = tf.transpose(tf.squeeze(outputs_q))\n",
    "doc_enc = tf.transpose(tf.squeeze(outputs_d))\n",
    "document_size = tf.shape(doc_enc)[1]\n",
    "\n",
    "\n",
    "# append sentinel vector for both encodings \n",
    "doc_enc_sentinel = tf.concat([doc_enc, sentinel_d], axis = 1)\n",
    "que_enc_sentinel = utils.non_linear_projection(tf.concat([que_enc, sentinel_q], axis = 1))\n",
    "\n",
    "\n",
    "# ===================  COATTENTION ENCODER ===================\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    # L \\in R(doc_size + 1) x (que_size + 1)\n",
    "    L = tf.matmul(doc_enc_sentinel, que_enc_sentinel, transpose_a = True)\n",
    "    A_Q = tf.nn.softmax(L, 0)\n",
    "    A_D = tf.nn.softmax(tf.transpose(L), 1)\n",
    "    C_Q = tf.matmul(doc_enc_sentinel, A_Q)\n",
    "    # C_D \\in R_2*lstm_size x (doc_size + 1)\n",
    "    C_D = tf.matmul(tf.concat([que_enc_sentinel, C_Q], axis = 0), A_D)\n",
    "\n",
    "    # bi_lstm_input = tf.unstack(tf.reshape(tf.transpose(tf.concat([doc_enc_sentinel, C_D], axis = 0)), [max_sequence_length + 1, 1, 3*lstm_size]))\n",
    "    # TODO Q: would we use single cell of two different\n",
    "    bi_lstm_input = tf.concat([doc_enc_sentinel, C_D], axis = 0)\n",
    "    bi_lstm_input = tf.transpose(bi_lstm_input)\n",
    "    bi_lstm_input = tf.reshape(bi_lstm_input, [1, max_sequence_length + 1, 3*lstm_size])\n",
    "    outputs_bi, output_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw = lstm_cenc_fw, \n",
    "        cell_bw = lstm_cenc_fw,\n",
    "      #  cell_bw = lstm_cenc_bw,\n",
    "        inputs = bi_lstm_input,\n",
    "      #  sequence_length = [12],\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    # we take first because of we feed to bi-RNN only one sentence\n",
    "    outputs_bi = tf.concat(outputs_bi, axis=2)[0]\n",
    "    print(outputs_bi)\n",
    "    U = tf.slice(outputs_bi, [0,0], [document_size, 2*lstm_size])\n",
    "    U = tf.transpose(U)\n",
    "#print(U)\n",
    "tf.summary.histogram('U', U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n"
     ]
    }
   ],
   "source": [
    "# ===================== DYNAMIC POINTING DECODER =============\n",
    "\n",
    "\n",
    "#scope = tf.get_variable_scope()\n",
    "#u_t = get_scope_variable(scope, 'hmn_u_t', [2*lstm_size, 1]) \n",
    "#h_i = get_scope_variable(scope, 'hmn_h_i', [lstm_size, 1 ]) \n",
    "#u_s_i = get_scope_variable(scope, 'hmn_u_s_i', [2*lstm_size, 1])\n",
    "#u_e_i = get_scope_variable(scope, 'hmn_u_e_i', [2*lstm_size, 1])\n",
    "\n",
    "\n",
    "#m_3 = HMN(U, h_i, u_s_i, u_e_i)\n",
    "#print(m_3)\n",
    "\n",
    "# returns tuple (scores_start, scores_end, strart_pos, start_end, new_lstm_state)\n",
    "def decoderIteration(U, lstm_state, start_pos, end_pos):\n",
    "    with tf.name_scope('Decoder_Iteration'):\n",
    "        with tf.name_scope('Next_Start'):\n",
    "            scores_start = hmn.HMN(U, \n",
    "                               tf.transpose(lstm_state.h), \n",
    "                               tf.slice(U, [0, start_pos], [lstm_size*2, 1]) ,\n",
    "                               tf.slice(U, [0, end_pos], [lstm_size*2, 1],) , \n",
    "                               'start',\n",
    "                                FLAGS)\n",
    "\n",
    "            new_start_pos = tf.to_int32(tf.argmax(scores_start, 0))\n",
    "\n",
    "        #print(lstm_state)\n",
    "        with tf.name_scope('Next_End'):\n",
    "            scores_end = hmn.HMN(U, \n",
    "                             tf.transpose(lstm_state.h), \n",
    "                             tf.slice(U, [0, new_start_pos], [lstm_size*2, 1],) ,\n",
    "                             tf.slice(U, [0, end_pos], [lstm_size*2, 1],), \n",
    "                            'end',\n",
    "                            FLAGS)\n",
    "            new_end_pos = tf.to_int32(tf.argmax(scores_end, 0))\n",
    "        \n",
    "        with tf.name_scope('LSTM_State_Update'):\n",
    "            lstm_input = tf.concat(\n",
    "                [tf.slice(U, [0, new_start_pos], [lstm_size*2, 1], name='slice-5'), tf.slice(U, [0, new_end_pos], [lstm_size*2, 1])],\n",
    "                axis = 0\n",
    "            )\n",
    "            output, new_lstm_state = lstm_dec(tf.reshape(lstm_input, [1, lstm_size*4]), lstm_state)\n",
    "        \n",
    "        #print(new_lstm_state)\n",
    "        return scores_start, scores_end, new_start_pos , new_end_pos, new_lstm_state\n",
    "\n",
    "\n",
    "\n",
    "#print(lstm_dec_state)\n",
    "\n",
    "with tf.name_scope('DYNAMIC_POINTING_DECODER'):\n",
    "    \n",
    "    start_pos = 0;\n",
    "    end_pos = 0;\n",
    "    sum_start_scores = tf.zeros([1, document_size])\n",
    "    sum_end_scores = tf.zeros([1, document_size])\n",
    "    lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "    \n",
    "    for step in range(max_decoder_iterations):\n",
    "        scores_start, scores_end, new_start_pos, new_end_pos, lstm_dec_state = decoderIteration(U, lstm_dec_state, start_pos, end_pos)\n",
    "        sum_start_scores = tf.add(sum_start_scores, scores_start)\n",
    "        sum_end_scores   = tf.add(sum_end_scores, scores_end)\n",
    "        if new_start_pos == start_pos and end_pos == new_end_pos : break\n",
    "        start_pos = new_start_pos\n",
    "        end_pos = new_end_pos\n",
    "\n",
    "    \n",
    "# loss and train step\n",
    "start_end_true = tf.placeholder(tf.int32, [2]);\n",
    "#end_true = tf.placeholder(tf.int32, ());\n",
    "onehot_labels = tf.one_hot(start_end_true, document_size)\n",
    "with tf.name_scope('Loss'):\n",
    "    sum_loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels,\n",
    "        tf.concat([sum_start_scores, sum_end_scores], axis=0))\n",
    "\n",
    "\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    with tf.name_scope('Prediction'):\n",
    "        pr_start_idx = tf.to_int32(tf.argmax(sum_start_scores, 0))[0]\n",
    "        pr_end_idx = tf.to_int32(tf.argmax(sum_end_scores, 0))[0]\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        accuracy = tf.py_func(utils.f1_score_int, [pr_start_idx, pr_end_idx, start_end_true[0], start_end_true[1]], tf.float64)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "print(sum_start_scores.get_shape())    \n",
    "    \n",
    "tf.summary.scalar('loss', sum_loss)\n",
    "with tf.name_scope('Train'):\n",
    "    train_step = optimizer.minimize(sum_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.0\n",
      "1 0.0\n",
      "2 0.0\n",
      "3 0.0\n",
      "4 0.0\n",
      "5 0.0\n",
      "6 0.0\n",
      "7 0.0\n",
      "8 2.87986\n",
      "9 0.0\n",
      "10 0.0\n",
      "11 0.0\n",
      "12 0.0\n",
      "AVG accuracy 0.0\n",
      "14 0.0\n",
      "15 2.5668\n",
      "16 3.02901\n",
      "17 0.0\n",
      "18 2.50792\n",
      "19 0.0\n",
      "20 0.0\n",
      "21 0.0\n",
      "22 3.22266\n",
      "23 0.0\n",
      "24 0.0\n",
      "25 0.0\n",
      "26 0.0\n",
      "AVG accuracy 0.0\n",
      "28 2.44018\n",
      "29 0.0\n",
      "30 1.37931\n",
      "31 0.0\n",
      "32 0.0\n",
      "33 0.0\n",
      "34 0.0\n",
      "35 0.0\n",
      "36 0.0\n",
      "37 0.0\n",
      "38 2.97288\n",
      "39 0.0\n",
      "40 1.36829\n",
      "AVG accuracy 0.1\n",
      "42 0.0\n",
      "43 0.0\n",
      "44 2.558\n",
      "45 3.18841\n",
      "46 2.23642\n",
      "47 3.07382\n",
      "48 0.0\n",
      "49 0.0\n",
      "50 0.0\n",
      "51 0.0\n",
      "52 2.821\n",
      "53 0.0\n",
      "54 0.0\n",
      "AVG accuracy 0.0\n",
      "56 0.0\n",
      "57 3.01401\n",
      "58 0.0\n",
      "59 2.92166\n",
      "60 0.0\n",
      "61 0.0\n",
      "62 0.0\n",
      "63 2.73473\n",
      "64 1.36766\n",
      "65 2.20237\n",
      "66 0.0\n",
      "67 0.0\n",
      "68 0.0\n",
      "AVG accuracy 0.0\n",
      "70 0.0\n",
      "71 0.0\n",
      "72 0.0\n",
      "73 0.0\n",
      "74 0.0\n",
      "75 0.0\n",
      "76 0.0\n",
      "77 2.67338\n",
      "78 0.0\n",
      "79 0.0\n",
      "80 2.91188\n",
      "81 0.0\n",
      "82 2.30916\n",
      "AVG accuracy 0.02\n",
      "84 0.0\n",
      "85 3.18423\n",
      "86 0.0\n",
      "87 0.0\n",
      "88 1.51271\n",
      "89 0.0\n",
      "90 1.6103\n",
      "91 0.0\n",
      "92 2.91596\n",
      "93 1.32687\n",
      "94 2.94194\n",
      "95 0.0\n",
      "96 0.0\n",
      "AVG accuracy 0.0\n",
      "98 0.0\n",
      "99 0.0\n",
      "100 0.0\n",
      "101 0.0\n",
      "102 3.09318\n",
      "103 0.0\n",
      "104 0.0\n",
      "105 2.46175\n",
      "106 2.66642\n",
      "107 0.0\n",
      "108 0.0\n",
      "109 0.0\n",
      "110 0.0\n",
      "AVG accuracy 0.0\n",
      "112 3.38755\n",
      "113 0.0\n",
      "114 0.0\n",
      "115 2.87326\n",
      "116 0.0\n",
      "117 3.22889\n",
      "118 0.0\n",
      "119 2.70839\n",
      "120 3.5417\n",
      "121 0.0\n",
      "122 0.0\n",
      "123 0.0\n",
      "124 0.0\n",
      "AVG accuracy 0.0\n",
      "126 0.0\n",
      "127 0.0\n",
      "128 3.60519\n",
      "129 0.0\n",
      "130 0.0\n",
      "131 0.0\n",
      "132 2.99138\n",
      "133 1.79517\n",
      "134 0.0\n",
      "135 0.0\n",
      "136 0.0\n",
      "137 0.0\n",
      "138 0.0\n",
      "AVG accuracy 0.0\n",
      "140 0.0\n",
      "141 0.0\n",
      "142 2.7684\n",
      "143 3.23541\n",
      "144 2.69576\n",
      "145 0.0\n",
      "146 2.11834\n",
      "147 0.0\n",
      "148 3.37216\n",
      "149 0.0\n",
      "150 0.0\n",
      "151 0.0\n",
      "152 0.0\n",
      "AVG accuracy 0.106666666667\n",
      "154 0.0\n",
      "155 0.0\n",
      "156 2.85923\n",
      "157 0.0\n",
      "158 3.79947\n",
      "159 2.68307\n",
      "160 0.0\n",
      "161 0.0\n",
      "162 0.0\n",
      "163 0.0\n",
      "164 3.43849\n",
      "165 2.14005\n",
      "166 0.0\n",
      "AVG accuracy 0.0\n",
      "168 0.0\n",
      "169 0.0\n",
      "170 2.70667\n",
      "171 0.0\n",
      "172 0.0\n",
      "173 0.0\n",
      "174 0.0\n",
      "175 3.6246\n",
      "176 0.0\n",
      "177 0.0\n",
      "178 0.0\n",
      "179 0.0\n",
      "180 0.0\n",
      "AVG accuracy 0.0\n",
      "182 0.0\n",
      "183 0.0\n",
      "184 2.14382\n",
      "185 1.99888\n",
      "186 0.0\n",
      "187 1.75698\n",
      "188 3.81379\n",
      "189 0.0\n",
      "190 0.0\n",
      "191 1.94141\n",
      "192 0.0\n",
      "193 0.0\n",
      "194 3.07945\n",
      "AVG accuracy 0.0\n",
      "196 1.63786\n",
      "197 0.0\n",
      "198 0.0\n",
      "199 2.62251\n",
      "200 0.0\n",
      "201 2.20085\n",
      "202 3.35681\n",
      "203 0.0\n",
      "204 0.0\n",
      "205 0.0\n",
      "206 0.0\n",
      "207 0.0\n",
      "208 0.0\n",
      "AVG accuracy 0.0\n",
      "210 1.77626\n",
      "211 0.0\n",
      "212 0.0\n",
      "213 0.0\n",
      "214 2.89733\n",
      "215 0.0\n",
      "216 0.0\n",
      "217 0.0\n",
      "218 0.0\n",
      "219 0.0\n",
      "220 1.44684\n",
      "221 4.40765\n",
      "222 3.80765\n",
      "AVG accuracy 0.1\n",
      "224 0.0\n",
      "225 0.0\n",
      "226 0.0\n",
      "227 0.0\n",
      "228 0.0\n",
      "229 0.0\n",
      "230 0.0\n",
      "231 4.46367\n",
      "232 0.0\n",
      "233 0.0\n",
      "234 1.62594\n",
      "235 0.0\n",
      "236 0.0\n",
      "AVG accuracy 0.09\n",
      "238 0.0\n",
      "239 0.0\n",
      "240 0.0\n",
      "241 0.0\n",
      "242 0.0\n",
      "243 3.38853\n",
      "244 0.0\n",
      "245 2.1215\n",
      "246 0.0\n",
      "247 0.0\n",
      "248 0.0\n",
      "249 0.0\n",
      "250 0.0\n",
      "AVG accuracy 0.133333333333\n",
      "252 0.0\n",
      "253 2.66105\n",
      "254 0.0\n",
      "255 0.0\n",
      "256 3.68482\n",
      "257 2.15564\n",
      "258 0.0\n",
      "259 0.0\n",
      "End\n"
     ]
    }
   ],
   "source": [
    "#=========== Training ==================\n",
    "\n",
    "\n",
    "def accuracyValidation(acc_batch_size):\n",
    "    acc_accum = 0\n",
    "    for step_accuracy_ in range(acc_batch_size):\n",
    "        start_true, end_true, doc, que, doc_v, que_v = sess.run(next_element_valid)\n",
    "        acc, stat, s, e = sess.run(\n",
    "            (accuracy, summary_op, pr_start_idx, pr_end_idx),\n",
    "            feed_dict={question_ph: [que_v], document_ph: [doc_v], start_end_true: [start_true, end_true]}\n",
    "        )\n",
    "        #print('Predicted answer', utils.substr(doc, s, e))\n",
    "        #print('True answer', utils.substr(doc, start_true, end_true))\n",
    "        writer.add_summary(stat,  step_* 10 + step_accuracy_)\n",
    "        acc_accum += acc;\n",
    "    print('AVG accuracy', acc_accum/acc_batch_size)\n",
    "\n",
    "def trainStep():\n",
    "    start_true, end_true, doc, que, doc_v, que_v = sess.run(next_element)\n",
    "    _,loss, stat = sess.run(\n",
    "        (train_step, sum_loss, summary_op), \n",
    "        feed_dict={question_ph: [que_v], document_ph: [doc_v], start_end_true: [start_true, end_true]}\n",
    "    )\n",
    "    print(step_, loss)\n",
    "    writer.add_summary(stat,  step_)\n",
    "\n",
    "\n",
    "dataset = ds.getDataset([\"./train_train_task_b.csv\"], max_sequence_length)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "dataset_validation = ds.getDataset([\"./valid_train_task_b.csv\"], max_sequence_length)\n",
    "iterator_valid = dataset_validation.make_one_shot_iterator()\n",
    "next_element_valid = iterator_valid.get_next()\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(FLAGS.log_path, sess.graph)\n",
    "    for epoch_ in range(max_epoch):\n",
    "        for step_ in range(260):\n",
    "            if step_ % 14 == 13:\n",
    "                # --------- ACCURACY -------------\n",
    "                accuracyValidation(acc_batch_size)\n",
    "  \n",
    "            else:\n",
    "                trainStep()\n",
    "                \n",
    "    print('End')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
