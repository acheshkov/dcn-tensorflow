{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import maxout\n",
    "import highway_maxout as hmn\n",
    "import utils\n",
    "import dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArgumentError",
     "evalue": "argument --maxout_layer_size: conflicting option string: --maxout_layer_size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-005775b10b60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#======= FLAGS ==========\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mFLAGS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maxout_layer_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Maxout layer size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'maxout_pooling_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Maxout pooling size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFINE_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'lstm_size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'LSTM cell internal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36mDEFINE_integer\u001b[0;34m(flag_name, default_value, docstring)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mdocstring\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m \u001b[0mhelpful\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0mexplaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[0muse\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m   \"\"\"\n\u001b[0;32m---> 96\u001b[0;31m   \u001b[0m_define_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflag_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/platform/flags.py\u001b[0m in \u001b[0;36m_define_helper\u001b[0;34m(flag_name, default_value, docstring, flagtype)\u001b[0m\n\u001b[1;32m     68\u001b[0m                               \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                               \u001b[0mhelp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                               type=flagtype)\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"length of metavar tuple does not match nargs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_argument_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1714\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption_strings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1716\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1717\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1718\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_positionals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1557\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ArgumentGroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1558\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1559\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0;31m# resolve any conflicts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_conflict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1369\u001b[0m         \u001b[0;31m# add to actions list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36m_check_conflict\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m   1504\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1505\u001b[0m             \u001b[0mconflict_handler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1506\u001b[0;31m             \u001b[0mconflict_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/argparse.py\u001b[0m in \u001b[0;36m_handle_conflict_error\u001b[0;34m(self, action, conflicting_actions)\u001b[0m\n\u001b[1;32m   1513\u001b[0m                                      \u001b[0;32mfor\u001b[0m \u001b[0moption_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m                                      in conflicting_actions])\n\u001b[0;32m-> 1515\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mconflict_string\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_handle_conflict_resolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument --maxout_layer_size: conflicting option string: --maxout_layer_size"
     ]
    }
   ],
   "source": [
    "#======= FLAGS ==========\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('maxout_layer_size', 8, 'Maxout layer size')\n",
    "tf.app.flags.DEFINE_integer('maxout_pooling_size', 16, 'Maxout pooling size')\n",
    "tf.app.flags.DEFINE_integer('lstm_size', 200, 'LSTM cell internal size')\n",
    "tf.app.flags.DEFINE_string('log_path', '/tmp/dcn', 'logs location')\n",
    "tf.app.flags.DEFINE_integer('acc_batch_size', 5, 'How many examples to use to calculate accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all variables\n",
    "tf.reset_default_graph();\n",
    "\n",
    "lstm_size = FLAGS.lstm_size\n",
    "acc_batch_size = FLAGS.acc_batch_size\n",
    "word_vector_size = 300\n",
    "maxout_pooling_size = FLAGS.maxout_pooling_size\n",
    "max_decoder_iterations = 4\n",
    "maxout_layer_size = FLAGS.maxout_layer_size;\n",
    "max_epoch = 1;\n",
    "max_sequence_length = 200\n",
    "#training_set_size = 100;\n",
    "\n",
    "# \n",
    "question_ph = tf.placeholder(tf.float32, [1, max_sequence_length, word_vector_size], name=\"q_input\")\n",
    "document_ph = tf.placeholder(tf.float32, [1, max_sequence_length, word_vector_size], name=\"d_input\")\n",
    "\n",
    "\n",
    "with tf.name_scope('ENCODER'):\n",
    "    # LSTM cell initialization\n",
    "    lstm = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm = tf.nn.rnn_cell.DropoutWrapper(cell=lstm, output_keep_prob=0.5)\n",
    "\n",
    "\n",
    "# LSTM cells for Bi-LSTM for COATINATION ENCODER\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_fw, output_keep_prob=0.5)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_bw, output_keep_prob=0.5)\n",
    "\n",
    "# create lstm cell for DYNAMIC POINTING DECODER\n",
    "lstm_dec = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# get lstm initial state of zeroes\n",
    "#lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "start_pos = 0; # generate random between (0, document_size-1)\n",
    "end_pos = 0;   # generate random between (0, document_size-1)\n",
    "\n",
    "# create sentinel vector variable for both encodings \n",
    "#with tf.variable_scope(\"scope1\") as scope:\n",
    "sentinel_q = tf.get_variable(\"sentinel_q\", [ lstm_size , 1], initializer = tf.random_normal_initializer())\n",
    "sentinel_d = tf.get_variable(\"sentinel_d\", [ lstm_size , 1], initializer = tf.random_normal_initializer()) \n",
    "\n",
    "tf.summary.histogram('sentinel_q', sentinel_q)\n",
    "tf.summary.histogram('sentinel_q_max', tf.reduce_max(sentinel_q))\n",
    "tf.summary.histogram('sentinel_d', sentinel_d)\n",
    "tf.summary.histogram('sentinel_d_max', tf.reduce_max(sentinel_d))\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Add:0\", shape=(200, 201), dtype=float32)\n",
      "Tensor(\"COATTENTION_ENCODER_1/strided_slice:0\", shape=(?, 400), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'U_max:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# r = lstm(inputs = tf.convert_to_tensor([[1,2], [2,3]], dtype=tf.float32), state = zero_state_q)\n",
    "\n",
    "def length(sequence):\n",
    "  used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "  length = tf.reduce_sum(used, 1)\n",
    "  length = tf.cast(length, tf.int32)\n",
    "  return length\n",
    "\n",
    "'''\n",
    "transform tensor of shape [1, question_size, word_vector_size] to list of tensors of shape [1, word_vector_size]\n",
    "of length question_size. first dimenstion is batch size = 1\n",
    "'''\n",
    "\n",
    "#print(tf.shape(question_ph)[1])\n",
    "#question_input = tf.unstack(question_ph, max_sequence_length, 1)\n",
    "#document_input = tf.unstack(document_ph, max_sequence_length, 1)\n",
    "#print(x)\n",
    "\n",
    "# we use the same LSTM for both encodings to share weights\n",
    "with tf.name_scope('ENCODER'):\n",
    "    with tf.name_scope('Q_ENC'):\n",
    "        outputs_q, state_q = tf.nn.dynamic_rnn(lstm, inputs = question_ph, sequence_length = length(question_ph), dtype=tf.float32)\n",
    "    with tf.name_scope('D_ENC'):\n",
    "        outputs_d, state_d = tf.nn.dynamic_rnn(lstm, inputs = document_ph, sequence_length = length(document_ph), dtype=tf.float32)\n",
    "\n",
    "\n",
    "document_size = length(document_ph)[0]\n",
    "question_size = length(question_ph)[0]\n",
    "doc_padding = tf.subtract([0, max_sequence_length], [0, document_size])\n",
    "que_padding = tf.subtract([0, max_sequence_length], [0, question_size])\n",
    "\n",
    "\n",
    "# \"squeeze\" transforms list of tensors of shape [1, lstm_size] of length L to tensor of shape [L, lstm_size]\n",
    "que_enc = tf.transpose(tf.squeeze(outputs_q))\n",
    "#que_enc = tf.slice(que_enc, [0,0], [lstm_size, question_size])\n",
    "#que_enc = tf.pad(que_enc, [[0,0], que_padding])\n",
    "#que_enc.set_shape([lstm_size, max_sequence_length])\n",
    "\n",
    "doc_enc = tf.transpose(tf.squeeze(outputs_d))\n",
    "doc_enc = tf.slice(doc_enc, [0,0], [lstm_size, document_size])\n",
    "#doc_enc = tf.pad(doc_enc, [[0,0], doc_padding])\n",
    "#doc_enc.set_shape([lstm_size, max_sequence_length])\n",
    "\n",
    "\n",
    "tf.summary.histogram('QUE_enc', que_enc)\n",
    "tf.summary.histogram('DOC_enc', doc_enc)\n",
    "tf.summary.histogram('DOC_enc_max', tf.reduce_max(doc_enc))\n",
    "tf.summary.histogram('QUE_enc_max', tf.reduce_max(que_enc))\n",
    "tf.summary.histogram('Document_size', document_size)\n",
    "tf.summary.histogram('Question_size', length(question_ph)[0])\n",
    "\n",
    "\n",
    "# append sentinel vector for both encodings \n",
    "doc_enc_sentinel = tf.concat([doc_enc, sentinel_d], axis = 1)\n",
    "que_enc_sentinel = utils.non_linear_projection(tf.concat([que_enc, sentinel_q], axis = 1))\n",
    "print(que_enc_sentinel)\n",
    "que_enc_sentinel = tf.slice(que_enc_sentinel, [0,0], [lstm_size, question_size + 1])\n",
    "\n",
    "# ===================  COATTENTION ENCODER ===================\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    # L \\in R(doc_size + 1) x (que_size + 1)\n",
    "    L = tf.matmul(doc_enc_sentinel, que_enc_sentinel, transpose_a = True)\n",
    "    A_Q = tf.nn.softmax(L, 0)\n",
    "    A_D = tf.nn.softmax(tf.transpose(L), 1)\n",
    "    C_Q = tf.matmul(doc_enc_sentinel, A_Q)\n",
    "    # C_D \\in R_2*lstm_size x (doc_size + 1)\n",
    "    C_D = tf.matmul(tf.concat([que_enc_sentinel, C_Q], axis = 0), A_D)\n",
    "\n",
    "    # bi_lstm_input = tf.unstack(tf.reshape(tf.transpose(tf.concat([doc_enc_sentinel, C_D], axis = 0)), [max_sequence_length + 1, 1, 3*lstm_size]))\n",
    "    # TODO Q: would we use single cell of two different\n",
    "    bi_lstm_input = tf.concat([doc_enc_sentinel, C_D], axis = 0)\n",
    "    bi_lstm_input = tf.transpose(bi_lstm_input)\n",
    "    bi_lstm_input = tf.reshape(bi_lstm_input, [1, document_size + 1, 3*lstm_size])\n",
    "    \n",
    "    tf.summary.histogram('bi_lstm_input', bi_lstm_input)\n",
    "    \n",
    "    outputs_bi, output_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw = lstm_cenc_fw, \n",
    "        cell_bw = lstm_cenc_bw,\n",
    "      #  cell_bw = lstm_cenc_bw,\n",
    "        inputs = bi_lstm_input,\n",
    "       # sequence_length = [document_size[0] + 1],\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    # we take first because of we feed to bi-RNN only one sentence\n",
    "    outputs_bi = tf.concat(outputs_bi, axis=2)[0]\n",
    "    print(outputs_bi)\n",
    "    U = tf.slice(outputs_bi, [0,0], [document_size, 2*lstm_size])\n",
    "    U = tf.transpose(U)\n",
    "#print(U)\n",
    "tf.summary.histogram('U', U)\n",
    "tf.summary.histogram('U_max', tf.reduce_max(U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n"
     ]
    }
   ],
   "source": [
    "# ===================== DYNAMIC POINTING DECODER =============\n",
    "\n",
    "\n",
    "#scope = tf.get_variable_scope()\n",
    "#u_t = get_scope_variable(scope, 'hmn_u_t', [2*lstm_size, 1]) \n",
    "#h_i = get_scope_variable(scope, 'hmn_h_i', [lstm_size, 1 ]) \n",
    "#u_s_i = get_scope_variable(scope, 'hmn_u_s_i', [2*lstm_size, 1])\n",
    "#u_e_i = get_scope_variable(scope, 'hmn_u_e_i', [2*lstm_size, 1])\n",
    "\n",
    "\n",
    "#m_3 = HMN(U, h_i, u_s_i, u_e_i)\n",
    "#print(m_3)\n",
    "\n",
    "# returns tuple (scores_start, scores_end, strart_pos, start_end, new_lstm_state)\n",
    "def decoderIteration(U, lstm_state, start_pos, end_pos):\n",
    "    with tf.name_scope('Decoder_Iteration'):\n",
    "        with tf.name_scope('Next_Start'):\n",
    "            scores_start = hmn.HMN(U, \n",
    "                               tf.transpose(lstm_state.h), \n",
    "                               tf.slice(U, [0, start_pos], [lstm_size*2, 1]) ,\n",
    "                               tf.slice(U, [0, end_pos], [lstm_size*2, 1]) , \n",
    "                               document_size,\n",
    "                               'start',\n",
    "                                FLAGS)\n",
    "\n",
    "            new_start_pos = tf.to_int32(tf.argmax(scores_start, 0))\n",
    "\n",
    "        #print(lstm_state)\n",
    "        with tf.name_scope('Next_End'):\n",
    "            scores_end = hmn.HMN(U, \n",
    "                             tf.transpose(lstm_state.h), \n",
    "                             tf.slice(U, [0, new_start_pos], [lstm_size*2, 1],) ,\n",
    "                             tf.slice(U, [0, end_pos], [lstm_size*2, 1]), \n",
    "                             document_size,\n",
    "                            'end',\n",
    "                            FLAGS)\n",
    "            new_end_pos = tf.to_int32(tf.argmax(scores_end, 0))\n",
    "        \n",
    "        with tf.name_scope('LSTM_State_Update'):\n",
    "            lstm_input = tf.concat(\n",
    "                [tf.slice(U, [0, new_start_pos], [lstm_size*2, 1], name='slice-5'), tf.slice(U, [0, new_end_pos], [lstm_size*2, 1])],\n",
    "                axis = 0\n",
    "            )\n",
    "            output, new_lstm_state = lstm_dec(tf.reshape(lstm_input, [1, lstm_size*4]), lstm_state)\n",
    "        \n",
    "        #print(new_lstm_state)\n",
    "        return scores_start, scores_end, new_start_pos , new_end_pos, new_lstm_state\n",
    "\n",
    "\n",
    "\n",
    "#print(lstm_dec_state)\n",
    "\n",
    "with tf.name_scope('DYNAMIC_POINTING_DECODER'):\n",
    "    \n",
    "    start_pos = 0;\n",
    "    end_pos = 0;\n",
    "    sum_start_scores = tf.zeros([1, document_size])\n",
    "    sum_end_scores = tf.zeros([1, document_size])\n",
    "    lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "    \n",
    "    for step in range(max_decoder_iterations):\n",
    "        scores_start, scores_end, new_start_pos, new_end_pos, lstm_dec_state = decoderIteration(U, lstm_dec_state, start_pos, end_pos)\n",
    "        sum_start_scores = tf.add(sum_start_scores, scores_start)\n",
    "        sum_end_scores   = tf.add(sum_end_scores, scores_end)\n",
    "        if new_start_pos == start_pos and end_pos == new_end_pos : break\n",
    "        start_pos = new_start_pos\n",
    "        end_pos = new_end_pos\n",
    "\n",
    "    \n",
    "# loss and train step\n",
    "start_end_true = tf.placeholder(tf.int32, [2]);\n",
    "#end_true = tf.placeholder(tf.int32, ());\n",
    "onehot_labels = tf.one_hot(start_end_true, document_size)\n",
    "with tf.name_scope('Loss'):\n",
    "    sum_loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels,\n",
    "        tf.concat([sum_start_scores, sum_end_scores], axis=0))\n",
    "\n",
    "\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    with tf.name_scope('Prediction'):\n",
    "        pr_start_idx = tf.to_int32(tf.argmax(sum_start_scores, 0))[0]\n",
    "        pr_end_idx = tf.to_int32(tf.argmax(sum_end_scores, 0))[0]\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        accuracy = tf.py_func(utils.f1_score_int, [pr_start_idx, pr_end_idx, start_end_true[0], start_end_true[1]], tf.float64)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "print(sum_start_scores.get_shape())    \n",
    "    \n",
    "tf.summary.scalar('loss', sum_loss)\n",
    "with tf.name_scope('Train'):\n",
    "    train_step = optimizer.minimize(sum_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVG accuracy 0.0\n",
      "10 4.17165\n",
      "20 4.89753\n",
      "30 2.29276\n",
      "40 5.00757\n",
      "AVG accuracy 0.0\n",
      "60 3.78262\n",
      "70 5.34856\n",
      "80 6.95125\n",
      "90 4.63988\n",
      "AVG accuracy 0.0\n",
      "110 6.19278\n",
      "120 5.31183\n",
      "130 0.0\n",
      "140 5.11788\n",
      "AVG accuracy 0.0\n",
      "160 4.32967\n",
      "170 3.91428\n",
      "180 5.19902\n",
      "190 5.58945\n",
      "AVG accuracy 0.2\n",
      "210 4.85122\n",
      "220 4.78566\n",
      "230 5.34193\n",
      "240 5.12569\n",
      "AVG accuracy 0.0\n",
      "260 4.58334\n",
      "270 4.24187\n",
      "280 4.37901\n",
      "290 0.0\n",
      "AVG accuracy 0.0\n",
      "310 6.74166\n",
      "320 2.87216\n",
      "330 4.85704\n",
      "340 0.0\n",
      "AVG accuracy 0.0\n",
      "360 6.37697\n",
      "370 6.85181\n",
      "380 6.08928\n",
      "390 5.43004\n",
      "AVG accuracy 0.0\n",
      "410 4.43693\n",
      "420 4.82073\n",
      "430 4.14617\n",
      "440 4.47102\n",
      "AVG accuracy 0.0\n",
      "460 4.36448\n",
      "470 5.97492\n",
      "480 5.49987\n",
      "490 11.1636\n",
      "AVG accuracy 0.0\n",
      "510 5.25182\n",
      "520 3.73654\n",
      "530 3.96798\n",
      "540 4.42093\n",
      "AVG accuracy 0.04\n",
      "560 5.10374\n",
      "570 3.49078\n",
      "580 6.79199\n",
      "590 2.06302\n",
      "AVG accuracy 0.0\n",
      "610 2.90701\n",
      "620 4.54583\n",
      "630 4.43065\n",
      "640 5.48313\n",
      "AVG accuracy 0.0\n",
      "660 4.56103\n",
      "670 4.25524\n",
      "680 4.97289\n",
      "690 4.40682\n",
      "AVG accuracy 0.0\n",
      "710 5.23093\n",
      "720 4.20972\n",
      "730 4.78875\n",
      "740 4.169\n",
      "AVG accuracy 0.0\n",
      "760 4.8849\n",
      "770 5.05093\n",
      "780 5.57241\n",
      "790 3.77978\n",
      "AVG accuracy 0.0\n",
      "810 4.91851\n",
      "820 5.54507\n",
      "830 3.57158\n",
      "840 4.53357\n",
      "AVG accuracy 0.0\n",
      "860 5.57\n",
      "870 5.14925\n",
      "880 5.40026\n",
      "890 4.53679\n"
     ]
    }
   ],
   "source": [
    "#=========== Training ==================\n",
    "\n",
    "\n",
    "def accuracyValidation(acc_batch_size, step):\n",
    "    acc_accum = 0\n",
    "    for step_accuracy_ in range(acc_batch_size):\n",
    "        start_true, end_true, doc, que, doc_v, que_v = sess.run(next_element_valid)\n",
    "        acc, stat, s, e = sess.run(\n",
    "            (accuracy, summary_op, pr_start_idx, pr_end_idx),\n",
    "            feed_dict={question_ph: [que_v], document_ph: [doc_v], start_end_true: [start_true, end_true]}\n",
    "        )\n",
    "        #print('Predicted answer', utils.substr(doc, s, e))\n",
    "        #print('True answer', utils.substr(doc, start_true, end_true))\n",
    "        writer.add_summary(stat,  step* 10 + step_accuracy_)\n",
    "        acc_accum += acc;\n",
    "    print('AVG accuracy', acc_accum/acc_batch_size)\n",
    "\n",
    "def trainStep(step):\n",
    "    start_true, end_true, doc, que, doc_v, que_v = sess.run(next_element)\n",
    "    \n",
    "    if start_true < 0 or end_true > max_sequence_length - 1: \n",
    "        print('Ignore step', start_true, end_true)\n",
    "        return\n",
    "    \n",
    "    _,loss, stat = sess.run(\n",
    "        (train_step, sum_loss, summary_op), \n",
    "        feed_dict={question_ph: [que_v], document_ph: [doc_v], start_end_true: [start_true, end_true]}\n",
    "    )\n",
    "    if step % 10 == 0: print(step, loss)\n",
    "    writer.add_summary(stat,  step)\n",
    "\n",
    "\n",
    "dataset = ds.getDataset([\"./train_train_task_b.csv\"], max_sequence_length)\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "dataset_validation = ds.getDataset([\"./valid_train_task_b.csv\"], max_sequence_length)\n",
    "iterator_valid = dataset_validation.make_one_shot_iterator()\n",
    "next_element_valid = iterator_valid.get_next()\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(FLAGS.log_path + \"/4\", sess.graph)\n",
    "    for epoch_ in range(max_epoch):\n",
    "        for step_ in range(2600):\n",
    "            if step_ % 50 == 0:\n",
    "                # --------- ACCURACY -------------\n",
    "                accuracyValidation(acc_batch_size, step_)\n",
    "  \n",
    "            else:\n",
    "                trainStep(step_)\n",
    "                \n",
    "    print('End')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
