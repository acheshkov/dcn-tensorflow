{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import maxout\n",
    "import highway_maxout as hmn\n",
    "import utils\n",
    "import dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#======= FLAGS ==========\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('maxout_layer_size', 50, 'Maxout layer size')\n",
    "tf.app.flags.DEFINE_integer('maxout_pooling_size', 4, 'Maxout pooling size')\n",
    "tf.app.flags.DEFINE_integer('lstm_size', 50, 'LSTM cell internal size')\n",
    "tf.app.flags.DEFINE_string('log_path', '/tmp/dcn', 'logs location')\n",
    "tf.app.flags.DEFINE_integer('acc_batch_size', 5, 'How many examples to use to calculate accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all variables\n",
    "tf.reset_default_graph();\n",
    "\n",
    "lstm_size = FLAGS.lstm_size\n",
    "acc_batch_size = FLAGS.acc_batch_size\n",
    "word_vector_size = 300\n",
    "maxout_pooling_size = FLAGS.maxout_pooling_size\n",
    "max_decoder_iterations = 4\n",
    "maxout_layer_size = FLAGS.maxout_layer_size;\n",
    "max_epoch = 1000;\n",
    "max_sequence_length = 80\n",
    "#training_set_size = 100;\n",
    "\n",
    "# \n",
    "question_ph = tf.placeholder(tf.float32, [1, max_sequence_length, word_vector_size], name=\"q_input\")\n",
    "document_ph = tf.placeholder(tf.float32, [1, max_sequence_length, word_vector_size], name=\"d_input\")\n",
    "\n",
    "\n",
    "with tf.name_scope('ENCODER'):\n",
    "    # LSTM cell initialization\n",
    "    lstm = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm = tf.nn.rnn_cell.DropoutWrapper(cell=lstm, output_keep_prob=0.5)\n",
    "\n",
    "\n",
    "# LSTM cells for Bi-LSTM for COATINATION ENCODER\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_fw, output_keep_prob=0.5)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_bw, output_keep_prob=0.5)\n",
    "\n",
    "# create lstm cell for DYNAMIC POINTING DECODER\n",
    "lstm_dec = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# get lstm initial state of zeroes\n",
    "#lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "start_pos = 0; # ?generate random between (0, document_size-1)\n",
    "end_pos = 0;   # ?generate random between (0, document_size-1)\n",
    "\n",
    "# create sentinel vector variable for both encodings \n",
    "#with tf.variable_scope(\"scope1\") as scope:\n",
    "sentinel_q = tf.get_variable(\"sentinel_q\", [ lstm_size , 1], initializer = tf.random_normal_initializer())\n",
    "sentinel_d = tf.get_variable(\"sentinel_d\", [ lstm_size , 1], initializer = tf.random_normal_initializer()) \n",
    "\n",
    "tf.summary.histogram('sentinel_q', sentinel_q)\n",
    "tf.summary.histogram('sentinel_q_max', tf.reduce_max(sentinel_q))\n",
    "tf.summary.histogram('sentinel_d', sentinel_d)\n",
    "tf.summary.histogram('sentinel_d_max', tf.reduce_max(sentinel_d))\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Slice_1:0\", shape=(?, ?), dtype=float32)\n",
      "Tensor(\"COATTENTION_ENCODER_1/strided_slice:0\", shape=(?, 100), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'U_max:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# r = lstm(inputs = tf.convert_to_tensor([[1,2], [2,3]], dtype=tf.float32), state = zero_state_q)\n",
    "\n",
    "def length(sequence):\n",
    "  used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "  length = tf.reduce_sum(used, 1)\n",
    "  length = tf.cast(length, tf.int32)\n",
    "  return length\n",
    "\n",
    "'''\n",
    "transform tensor of shape [1, question_size, word_vector_size] to list of tensors of shape [1, word_vector_size]\n",
    "of length question_size. first dimenstion is batch size = 1\n",
    "'''\n",
    "\n",
    "#print(tf.shape(question_ph)[1])\n",
    "#question_input = tf.unstack(question_ph, max_sequence_length, 1)\n",
    "#document_input = tf.unstack(document_ph, max_sequence_length, 1)\n",
    "#print(x)\n",
    "\n",
    "# we use the same LSTM for both encodings to share weights\n",
    "with tf.name_scope('ENCODER'):\n",
    "    with tf.name_scope('Q_ENC'):\n",
    "        outputs_q, state_q = tf.nn.dynamic_rnn(lstm, inputs = question_ph, sequence_length = length(question_ph), dtype=tf.float32)\n",
    "    with tf.name_scope('D_ENC'):\n",
    "        outputs_d, state_d = tf.nn.dynamic_rnn(lstm, inputs = document_ph, sequence_length = length(document_ph), dtype=tf.float32)\n",
    "\n",
    "\n",
    "document_size = length(document_ph)[0]\n",
    "question_size = length(question_ph)[0]\n",
    "doc_padding = tf.subtract([0, max_sequence_length], [0, document_size])\n",
    "que_padding = tf.subtract([0, max_sequence_length], [0, question_size])\n",
    "\n",
    "\n",
    "# \"squeeze\" transforms list of tensors of shape [1, lstm_size] of length L to tensor of shape [L, lstm_size]\n",
    "que_enc = tf.transpose(tf.squeeze(outputs_q))\n",
    "que_enc = tf.slice(que_enc, [0,0], [lstm_size, question_size])\n",
    "que_enc_sentinel = tf.concat([que_enc, sentinel_q], axis = 1)\n",
    "que_enc_sentinel = tf.pad(que_enc_sentinel, [[0,0], que_padding])\n",
    "que_enc_sentinel.set_shape([lstm_size, max_sequence_length + 1])\n",
    "que_enc_sentinel = utils.non_linear_projection(que_enc_sentinel)\n",
    "que_enc_sentinel = tf.slice(que_enc_sentinel, [0,0], [lstm_size, question_size + 1])\n",
    "#que_enc_sentinel.set_shape([lstm_size, max_sequence_length + 1])\n",
    "\n",
    "doc_enc = tf.transpose(tf.squeeze(outputs_d))\n",
    "doc_enc = tf.slice(doc_enc, [0,0], [lstm_size, document_size])\n",
    "#doc_enc = tf.pad(doc_enc, [[0,0], doc_padding])\n",
    "#doc_enc.set_shape([lstm_size, max_sequence_length])\n",
    "\n",
    "\n",
    "tf.summary.histogram('QUE_enc', que_enc)\n",
    "tf.summary.histogram('DOC_enc', doc_enc)\n",
    "tf.summary.histogram('DOC_enc_max', tf.reduce_max(doc_enc))\n",
    "tf.summary.histogram('QUE_enc_max', tf.reduce_max(que_enc))\n",
    "tf.summary.histogram('Document_size', document_size)\n",
    "tf.summary.histogram('Question_size', length(question_ph)[0])\n",
    "\n",
    "\n",
    "# append sentinel vector for both encodings \n",
    "doc_enc_sentinel = tf.concat([doc_enc, sentinel_d], axis = 1)\n",
    "#que_enc_sentinel = utils.non_linear_projection(tf.concat([que_enc, sentinel_q], axis = 1))\n",
    "print(que_enc_sentinel)\n",
    "#que_enc_sentinel = tf.slice(que_enc_sentinel, [0,0], [lstm_size, question_size + 1])\n",
    "\n",
    "# ===================  COATTENTION ENCODER ===================\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    # L \\in R(doc_size + 1) x (que_size + 1)\n",
    "    L = tf.matmul(doc_enc_sentinel, que_enc_sentinel, transpose_a = True)\n",
    "    A_Q = tf.nn.softmax(L, 0)\n",
    "    A_D = tf.nn.softmax(tf.transpose(L), 1)\n",
    "    C_Q = tf.matmul(doc_enc_sentinel, A_Q)\n",
    "    # C_D \\in R_2*lstm_size x (doc_size + 1)\n",
    "    C_D = tf.matmul(tf.concat([que_enc_sentinel, C_Q], axis = 0), A_D)\n",
    "\n",
    "    # bi_lstm_input = tf.unstack(tf.reshape(tf.transpose(tf.concat([doc_enc_sentinel, C_D], axis = 0)), [max_sequence_length + 1, 1, 3*lstm_size]))\n",
    "    # TODO Q: would we use single cell of two different\n",
    "    bi_lstm_input = tf.concat([doc_enc_sentinel, C_D], axis = 0)\n",
    "    bi_lstm_input = tf.transpose(bi_lstm_input)\n",
    "    bi_lstm_input = tf.reshape(bi_lstm_input, [1, document_size + 1, 3*lstm_size])\n",
    "    \n",
    "    tf.summary.histogram('bi_lstm_input', bi_lstm_input)\n",
    "    \n",
    "    outputs_bi, output_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw = lstm_cenc_fw, \n",
    "        cell_bw = lstm_cenc_bw,\n",
    "      #  cell_bw = lstm_cenc_bw,\n",
    "        inputs = bi_lstm_input,\n",
    "       # sequence_length = [document_size[0] + 1],\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    # we take first because of we feed to bi-RNN only one sentence\n",
    "    outputs_bi = tf.concat(outputs_bi, axis=2)[0]\n",
    "    print(outputs_bi)\n",
    "    U = tf.slice(outputs_bi, [0,0], [document_size, 2*lstm_size])\n",
    "    U = tf.transpose(U)\n",
    "#print(U)\n",
    "tf.summary.histogram('U', U)\n",
    "tf.summary.histogram('U_max', tf.reduce_max(U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n"
     ]
    }
   ],
   "source": [
    "# ===================== DYNAMIC POINTING DECODER =============\n",
    "\n",
    "\n",
    "#scope = tf.get_variable_scope()\n",
    "#u_t = get_scope_variable(scope, 'hmn_u_t', [2*lstm_size, 1]) \n",
    "#h_i = get_scope_variable(scope, 'hmn_h_i', [lstm_size, 1 ]) \n",
    "#u_s_i = get_scope_variable(scope, 'hmn_u_s_i', [2*lstm_size, 1])\n",
    "#u_e_i = get_scope_variable(scope, 'hmn_u_e_i', [2*lstm_size, 1])\n",
    "\n",
    "\n",
    "#m_3 = HMN(U, h_i, u_s_i, u_e_i)\n",
    "#print(m_3)\n",
    "\n",
    "# returns tuple (scores_start, scores_end, strart_pos, start_end, new_lstm_state)\n",
    "def decoderIteration(U, lstm_state, start_pos, end_pos, iter_number):\n",
    "    with tf.name_scope('Decoder_Iteration'):\n",
    "        with tf.name_scope('Next_Start'):\n",
    "            scores_start = hmn.HMN(U, \n",
    "                               tf.transpose(lstm_state.h), \n",
    "                               tf.slice(U, [0, start_pos], [lstm_size*2, 1]) ,\n",
    "                               tf.slice(U, [0, end_pos], [lstm_size*2, 1]) , \n",
    "                               document_size,\n",
    "                               'start',\n",
    "                                FLAGS,\n",
    "                                iter_number)\n",
    "\n",
    "            new_start_pos = tf.to_int32(tf.argmax(scores_start, 0))\n",
    "\n",
    "        #print(lstm_state)\n",
    "        with tf.name_scope('Next_End'):\n",
    "            scores_end = hmn.HMN(U, \n",
    "                             tf.transpose(lstm_state.h), \n",
    "                             tf.slice(U, [0, new_start_pos], [lstm_size*2, 1],) ,\n",
    "                             tf.slice(U, [0, end_pos], [lstm_size*2, 1]), \n",
    "                             document_size,\n",
    "                            'end',\n",
    "                            FLAGS,\n",
    "                            iter_number)\n",
    "            new_end_pos = tf.to_int32(tf.argmax(scores_end, 0))\n",
    "        \n",
    "        with tf.name_scope('LSTM_State_Update'):\n",
    "            lstm_input = tf.concat(\n",
    "                [tf.slice(U, [0, new_start_pos], [lstm_size*2, 1], name='slice-5'), tf.slice(U, [0, new_end_pos], [lstm_size*2, 1])],\n",
    "                axis = 0\n",
    "            )\n",
    "            output, new_lstm_state = lstm_dec(tf.reshape(lstm_input, [1, lstm_size*4]), lstm_state)\n",
    "        \n",
    "        #print(new_lstm_state)\n",
    "        return scores_start, scores_end, new_start_pos , new_end_pos, new_lstm_state\n",
    "\n",
    "\n",
    "\n",
    "#print(lstm_dec_state)\n",
    "\n",
    "with tf.name_scope('DYNAMIC_POINTING_DECODER'):\n",
    "    \n",
    "    start_pos = 0;\n",
    "    end_pos = 0;\n",
    "    sum_start_scores = tf.zeros([1, document_size])\n",
    "    sum_end_scores = tf.zeros([1, document_size])\n",
    "    lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "    \n",
    "    for step in range(max_decoder_iterations):\n",
    "        scores_start, scores_end, new_start_pos, new_end_pos, lstm_dec_state = decoderIteration(U, lstm_dec_state, start_pos, end_pos, step + 1)\n",
    "        sum_start_scores = tf.add(sum_start_scores, scores_start)\n",
    "        sum_end_scores   = tf.add(sum_end_scores, scores_end)\n",
    "        if new_start_pos == start_pos and end_pos == new_end_pos : break\n",
    "        start_pos = new_start_pos\n",
    "        end_pos = new_end_pos\n",
    "\n",
    "    \n",
    "# loss and train step\n",
    "start_end_true = tf.placeholder(tf.int32, [2]);\n",
    "#end_true = tf.placeholder(tf.int32, ());\n",
    "onehot_labels = tf.one_hot(start_end_true, document_size)\n",
    "with tf.name_scope('Loss'):\n",
    "    sum_loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels,\n",
    "        tf.concat([sum_start_scores, sum_end_scores], axis=0))\n",
    "\n",
    "\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    with tf.name_scope('Prediction'):\n",
    "        pr_start_idx = tf.to_int32(tf.argmax(sum_start_scores, 1))[0]\n",
    "        pr_end_idx = tf.to_int32(tf.argmax(sum_end_scores, 1))[0]\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        accuracy = tf.py_func(utils.f1_score_int, [pr_start_idx, pr_end_idx, start_end_true[0], start_end_true[1]], tf.float64)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "print(sum_start_scores.get_shape())    \n",
    "    \n",
    "tf.summary.scalar('loss', sum_loss)\n",
    "with tf.name_scope('Train'):\n",
    "    train_step = optimizer.minimize(sum_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 41 8 68 69\n",
      "acc 15 13 40 41\n",
      "acc 25 61 43 45\n",
      "acc 17 4 12 13\n",
      "acc 17 32 61 63\n",
      "AVG accuracy 0.03\n",
      "acc 55 3 58 62\n",
      "acc 19 19 25 37\n",
      "acc 25 61 9 10\n",
      "acc 53 30 53 57\n",
      "acc 41 8 30 33\n",
      "AVG accuracy 0.0\n",
      "acc 41 8 54 56\n",
      "acc 28 19 54 56\n",
      "acc 57 60 7 8\n",
      "acc 15 8 7 9\n",
      "acc 55 3 61 66\n",
      "AVG accuracy 0.0\n",
      "acc 5 3 7 7\n",
      "acc 63 30 30 30\n",
      "acc 64 61 49 50\n",
      "acc 5 3 9 10\n",
      "acc 42 16 67 74\n",
      "AVG accuracy 0.0\n",
      "acc 64 61 0 0\n",
      "acc 15 28 21 25\n",
      "acc 41 76 5 7\n",
      "acc 35 4 7 9\n",
      "acc 56 17 29 32\n",
      "AVG accuracy 0.105263157895\n",
      "acc 15 18 16 16\n",
      "acc 56 17 21 23\n",
      "acc 37 3 24 25\n",
      "acc 37 3 66 70\n",
      "acc 53 3 9 14\n",
      "AVG accuracy 0.08\n",
      "acc 11 12 71 71\n",
      "acc 57 60 45 51\n",
      "acc 13 72 33 36\n",
      "acc 17 8 31 33\n",
      "acc 41 40 33 35\n",
      "AVG accuracy 0.025\n",
      "acc 17 8 33 33\n",
      "acc 53 52 6 8\n",
      "acc 17 8 48 49\n",
      "acc 17 8 11 14\n",
      "acc 11 12 26 26\n",
      "AVG accuracy 0.0\n",
      "acc 41 8 16 23\n",
      "acc 41 44 23 24\n",
      "acc 61 4 38 40\n",
      "acc 13 72 74 78\n",
      "acc 41 44 4 7\n",
      "AVG accuracy 0.0\n",
      "acc 17 8 75 77\n",
      "acc 13 72 47 48\n",
      "acc 35 4 1 1\n",
      "acc 53 18 54 56\n",
      "acc 53 38 35 37\n",
      "AVG accuracy 0.0129032258065\n",
      "acc 53 18 0 8\n",
      "acc 41 67 47 50\n",
      "acc 19 74 29 32\n",
      "acc 28 74 51 54\n",
      "acc 35 4 66 68\n",
      "AVG accuracy 0.109652118912\n",
      "acc 11 12 37 39\n",
      "acc 63 30 45 48\n",
      "acc 15 18 34 35\n",
      "acc 13 72 37 37\n",
      "acc 13 72 34 35\n",
      "AVG accuracy 0.0194606028556\n",
      "acc 0 61 44 45\n",
      "acc 55 3 22 28\n",
      "acc 13 72 31 35\n",
      "acc 53 11 73 73\n",
      "acc 53 30 8 10\n",
      "AVG accuracy 0.0432692307692\n",
      "acc 28 10 23 23\n",
      "acc 28 74 10 13\n",
      "acc 17 8 65 66\n",
      "acc 53 38 45 46\n",
      "acc 7 38 20 29\n",
      "AVG accuracy 0.0952380952381\n",
      "acc 3 34 58 59\n",
      "acc 0 61 41 42\n",
      "acc 28 74 58 62\n",
      "acc 53 30 64 76\n",
      "acc 41 50 58 63\n",
      "AVG accuracy 0.0509615384615\n",
      "acc 29 1 37 39\n",
      "acc 15 60 76 78\n",
      "acc 1 18 35 37\n",
      "acc 17 8 41 42\n",
      "acc 15 34 48 52\n",
      "AVG accuracy 0.0\n",
      "acc 21 50 23 24\n",
      "acc 56 62 30 32\n",
      "acc 0 61 13 17\n",
      "acc 11 12 9 13\n",
      "acc 63 30 20 26\n",
      "AVG accuracy 0.169136460554\n",
      "acc 37 3 45 46\n",
      "acc 56 62 7 8\n",
      "acc 53 38 57 65\n",
      "acc 35 20 14 17\n",
      "acc 28 16 43 47\n",
      "AVG accuracy 0.0\n",
      "acc 15 34 0 3\n",
      "acc 21 50 0 1\n",
      "acc 11 12 48 53\n",
      "acc 17 8 36 37\n",
      "acc 35 4 58 62\n",
      "AVG accuracy 0.0\n",
      "acc 53 3 25 29\n",
      "acc 35 4 39 41\n",
      "acc 50 41 6 11\n",
      "acc 0 6 58 67\n",
      "acc 19 60 6 11\n",
      "AVG accuracy 0.0\n",
      "acc 23 12 24 28\n",
      "acc 13 72 16 17\n",
      "acc 11 12 25 25\n",
      "acc 17 8 13 19\n",
      "acc 13 72 8 8\n",
      "AVG accuracy 0.0129032258065\n",
      "acc 28 16 63 65\n",
      "acc 63 52 3 4\n",
      "acc 20 3 34 36\n",
      "acc 19 38 33 36\n",
      "acc 28 16 55 57\n",
      "AVG accuracy 0.0666666666667\n",
      "acc 35 4 43 44\n",
      "acc 35 4 37 43\n",
      "acc 28 16 71 75\n",
      "acc 25 12 31 37\n",
      "acc 5 0 10 11\n",
      "AVG accuracy 0.0\n",
      "acc 50 27 13 15\n",
      "acc 15 34 10 12\n",
      "acc 17 8 59 60\n",
      "acc 35 4 33 35\n",
      "acc 56 62 32 34\n",
      "AVG accuracy 0.0\n",
      "acc 48 16 69 71\n",
      "acc 19 44 51 56\n",
      "acc 20 60 13 13\n",
      "acc 17 60 12 19\n",
      "acc 29 28 18 20\n",
      "AVG accuracy 0.0230769230769\n",
      "acc 40 10 58 61\n",
      "acc 53 52 51 65\n",
      "acc 1 4 2 3\n",
      "acc 5 0 41 44\n",
      "acc 1 64 59 64\n",
      "AVG accuracy 0.167619047619\n",
      "acc 51 19 30 32\n",
      "acc 0 15 8 8\n",
      "acc 21 72 13 19\n",
      "acc 16 33 33 39\n",
      "acc 0 15 52 56\n",
      "AVG accuracy 0.0395294117647\n",
      "acc 5 9 0 0\n",
      "acc 56 60 71 78\n",
      "acc 16 45 68 73\n",
      "acc 43 12 59 60\n",
      "acc 8 15 3 5\n",
      "AVG accuracy 0.0\n",
      "acc 53 10 57 60\n",
      "acc 28 9 7 7\n",
      "acc 36 4 9 12\n",
      "acc 4 11 36 38\n",
      "acc 61 0 41 42\n",
      "AVG accuracy 0.0\n",
      "acc 45 39 0 3\n",
      "acc 7 7 7 12\n",
      "acc 47 7 0 2\n",
      "acc 45 45 50 55\n",
      "acc 48 16 0 1\n",
      "AVG accuracy 0.0571428571429\n",
      "acc 27 28 8 9\n",
      "acc 8 21 10 12\n",
      "acc 67 4 74 75\n",
      "acc 16 35 41 41\n",
      "acc 48 17 11 13\n",
      "AVG accuracy 0.0705882352941\n",
      "acc 8 19 0 1\n",
      "acc 28 72 20 25\n",
      "acc 15 10 71 72\n",
      "acc 28 16 25 27\n",
      "acc 48 74 29 34\n",
      "AVG accuracy 0.0\n",
      "acc 8 9 49 51\n",
      "acc 8 15 24 26\n",
      "acc 4 11 44 46\n",
      "acc 28 49 54 54\n",
      "acc 28 72 56 58\n",
      "AVG accuracy 0.025\n",
      "acc 53 10 31 36\n",
      "acc 48 49 34 36\n",
      "acc 48 9 73 78\n",
      "acc 36 12 37 40\n",
      "acc 28 16 8 16\n",
      "AVG accuracy 0.0\n",
      "acc 26 5 32 41\n",
      "acc 16 10 65 66\n",
      "acc 0 15 5 6\n",
      "acc 19 9 0 5\n",
      "acc 27 28 14 15\n",
      "AVG accuracy 0.0444444444444\n",
      "acc 27 8 18 20\n",
      "acc 17 8 37 38\n",
      "acc 0 73 0 3\n",
      "acc 16 41 18 20\n",
      "acc 16 28 61 70\n",
      "AVG accuracy 0.0618921308576\n",
      "acc 0 17 5 7\n",
      "acc 1 40 38 39\n",
      "acc 17 28 19 24\n",
      "acc 1 10 6 7\n",
      "acc 31 5 72 74\n",
      "AVG accuracy 0.27619047619\n",
      "acc 0 21 60 62\n",
      "acc 0 15 13 24\n",
      "acc 17 28 18 21\n",
      "acc 6 66 69 70\n",
      "acc 19 9 46 48\n",
      "AVG accuracy 0.142857142857\n",
      "acc 6 62 63 64\n",
      "acc 19 9 36 37\n",
      "acc 26 28 11 12\n",
      "acc 20 44 27 29\n",
      "acc 0 1 11 11\n",
      "AVG accuracy 0.0428571428571\n",
      "Epoch 0 completed\n",
      "acc 0 15 29 33\n",
      "acc 5 0 75 78\n",
      "acc 26 52 20 22\n",
      "acc 0 12 6 7\n",
      "acc 0 35 58 59\n",
      "AVG accuracy 0.0533333333333\n",
      "acc 8 19 42 45\n",
      "acc 19 21 4 5\n",
      "acc 7 7 9 11\n",
      "acc 7 7 27 28\n",
      "acc 7 7 47 47\n",
      "AVG accuracy 0.0\n",
      "acc 0 19 54 59\n",
      "acc 4 4 37 40\n",
      "acc 15 34 40 46\n",
      "acc 26 28 3 7\n",
      "acc 8 22 12 13\n",
      "AVG accuracy 0.0470588235294\n",
      "acc 6 4 9 13\n",
      "acc 2 15 38 46\n",
      "acc 16 26 31 35\n",
      "acc 21 0 29 29\n",
      "acc 0 15 63 69\n",
      "AVG accuracy 0.0\n",
      "acc 53 7 9 16\n",
      "acc 5 4 8 9\n",
      "acc 0 5 67 72\n",
      "acc 30 8 34 40\n",
      "acc 0 16 5 11\n",
      "AVG accuracy 0.116666666667\n",
      "acc 11 34 37 41\n",
      "acc 0 17 20 21\n",
      "acc 1 4 44 49\n",
      "acc 21 7 1 3\n",
      "acc 3 7 5 7\n",
      "AVG accuracy 0.15\n",
      "acc 0 8 63 69\n",
      "acc 0 15 26 26\n",
      "acc 0 20 0 5\n",
      "acc 0 14 52 56\n",
      "acc 0 5 50 53\n",
      "AVG accuracy 0.0888888888889\n",
      "acc 1 0 11 13\n",
      "acc 0 78 3 4\n",
      "acc 12 70 46 54\n",
      "acc 0 14 59 61\n",
      "acc 30 28 10 22\n",
      "AVG accuracy 0.0628177196805\n",
      "acc 0 7 38 42\n",
      "acc 0 8 24 28\n",
      "acc 0 4 0 2\n",
      "acc 0 2 32 40\n",
      "acc 4 17 7 10\n",
      "AVG accuracy 0.238888888889\n",
      "acc 4 51 19 20\n",
      "acc 1 15 7 8\n",
      "acc 2 4 21 22\n",
      "acc 9 72 28 30\n",
      "acc 45 56 57 57\n",
      "AVG accuracy 0.0809692712906\n",
      "acc 35 0 29 29\n",
      "acc 7 2 37 41\n",
      "acc 28 9 34 39\n",
      "acc 0 8 45 46\n",
      "acc 27 8 60 61\n",
      "AVG accuracy 0.0\n",
      "acc 0 8 3 5\n",
      "acc 20 2 71 72\n",
      "acc 20 2 2 7\n",
      "acc 48 53 13 15\n",
      "acc 28 72 2 2\n",
      "AVG accuracy 0.1\n",
      "acc 28 9 33 35\n",
      "acc 0 51 42 44\n",
      "acc 49 8 3 3\n",
      "acc 26 51 40 41\n",
      "acc 4 17 10 10\n",
      "AVG accuracy 0.0770562770563\n",
      "acc 1 4 0 0\n",
      "acc 25 51 65 67\n",
      "acc 25 51 0 0\n",
      "acc 27 29 0 0\n",
      "acc 0 1 68 70\n",
      "AVG accuracy 0.0\n",
      "acc 7 24 45 49\n",
      "acc 0 2 10 11\n",
      "acc 20 2 57 57\n",
      "acc 1 36 38 42\n",
      "acc 39 48 30 32\n",
      "AVG accuracy 0.0\n",
      "acc 8 9 71 71\n",
      "acc 37 21 5 7\n",
      "acc 0 3 15 15\n",
      "acc 0 3 41 43\n",
      "acc 1 4 24 26\n",
      "AVG accuracy 0.0\n",
      "acc 28 47 32 38\n",
      "acc 0 36 72 72\n",
      "acc 30 8 48 49\n",
      "acc 26 19 28 31\n",
      "acc 4 2 11 20\n",
      "AVG accuracy 0.103703703704\n",
      "acc 13 10 17 20\n",
      "acc 37 9 52 53\n",
      "acc 8 19 5 5\n",
      "acc 0 41 30 32\n",
      "acc 0 20 47 48\n",
      "AVG accuracy 0.0266666666667\n",
      "acc 1 8 9 14\n",
      "acc 2 6 69 69\n",
      "acc 11 0 26 28\n",
      "acc 37 26 35 41\n",
      "acc 0 8 28 42\n",
      "AVG accuracy 0.0\n",
      "acc 0 60 59 60\n",
      "acc 0 41 57 58\n",
      "acc 9 4 22 22\n",
      "acc 5 0 7 12\n",
      "acc 21 28 72 74\n",
      "AVG accuracy 0.0126984126984\n",
      "acc 1 8 36 41\n",
      "acc 3 26 45 46\n",
      "acc 5 0 43 44\n",
      "acc 9 28 22 24\n",
      "acc 8 30 59 60\n",
      "AVG accuracy 0.0521739130435\n",
      "acc 0 8 8 10\n",
      "acc 26 6 41 45\n",
      "acc 6 18 45 50\n",
      "acc 0 8 34 36\n",
      "acc 0 15 7 7\n",
      "AVG accuracy 0.056862745098\n",
      "acc 0 3 1 4\n",
      "acc 0 42 67 73\n",
      "acc 8 9 0 1\n",
      "acc 8 30 50 54\n",
      "acc 8 26 12 12\n",
      "AVG accuracy 0.17\n",
      "acc 0 16 18 19\n",
      "acc 0 2 13 15\n",
      "acc 21 7 41 42\n",
      "acc 1 8 30 34\n",
      "acc 0 3 46 48\n",
      "AVG accuracy 0.0\n",
      "acc 0 8 59 65\n",
      "acc 2 2 48 52\n",
      "acc 0 9 76 78\n",
      "acc 2 7 27 28\n",
      "acc 20 4 7 8\n",
      "AVG accuracy 0.0\n",
      "acc 0 0 66 66\n",
      "acc 0 20 38 40\n",
      "acc 2 0 66 67\n",
      "acc 2 2 5 7\n",
      "acc 38 4 17 23\n",
      "AVG accuracy 0.0\n",
      "acc 8 13 12 19\n",
      "acc 0 0 0 0\n",
      "acc 0 8 0 4\n",
      "acc 48 9 68 69\n",
      "acc 2 19 23 25\n",
      "AVG accuracy 0.4\n",
      "acc 0 9 8 15\n",
      "acc 0 9 14 16\n",
      "acc 5 9 24 26\n",
      "acc 27 8 44 44\n",
      "acc 0 9 4 6\n",
      "AVG accuracy 0.136752136752\n",
      "acc 0 8 3 6\n",
      "acc 0 15 3 3\n",
      "acc 8 19 7 9\n",
      "acc 3 2 40 43\n",
      "acc 26 55 50 57\n",
      "AVG accuracy 0.263097562912\n",
      "acc 61 19 0 2\n",
      "acc 3 6 23 24\n",
      "acc 2 27 53 54\n",
      "acc 38 44 39 40\n",
      "acc 20 44 33 35\n",
      "AVG accuracy 0.131746031746\n",
      "acc 0 10 0 3\n",
      "acc 26 8 7 13\n",
      "acc 28 2 48 50\n",
      "acc 20 19 61 66\n",
      "acc 6 4 8 12\n",
      "AVG accuracy 0.106666666667\n",
      "acc 20 2 52 54\n",
      "acc 6 36 26 26\n",
      "acc 20 44 7 9\n",
      "acc 0 35 9 12\n",
      "acc 8 30 5 8\n",
      "AVG accuracy 0.0673148148148\n",
      "acc 35 4 13 13\n",
      "acc 13 72 13 15\n",
      "acc 3 4 5 5\n",
      "acc 28 47 24 27\n",
      "acc 3 10 42 42\n",
      "AVG accuracy 0.0190476190476\n",
      "acc 14 19 10 11\n",
      "acc 3 26 38 43\n",
      "acc 15 10 44 46\n",
      "acc 9 4 71 74\n",
      "acc 0 15 62 64\n",
      "AVG accuracy 0.0\n",
      "acc 3 42 48 49\n",
      "acc 8 9 42 42\n",
      "acc 0 8 15 15\n",
      "acc 0 19 40 44\n",
      "acc 0 0 17 22\n",
      "AVG accuracy 0.0\n",
      "acc 6 34 25 26\n",
      "acc 8 3 63 63\n",
      "acc 0 13 61 62\n",
      "acc 0 20 21 25\n",
      "acc 22 60 36 46\n",
      "AVG accuracy 0.113806451613\n",
      "acc 0 8 71 73\n",
      "acc 1 26 66 71\n",
      "acc 13 7 5 12\n",
      "acc 19 9 72 73\n",
      "acc 0 20 10 15\n",
      "AVG accuracy 0.0888888888889\n",
      "acc 19 9 36 39\n",
      "acc 13 10 62 63\n",
      "acc 26 8 5 6\n",
      "acc 11 7 21 23\n",
      "acc 26 15 21 24\n",
      "AVG accuracy 0.0\n",
      "acc 2 19 0 1\n",
      "acc 0 19 35 39\n",
      "acc 4 19 42 43\n",
      "acc 0 9 38 41\n",
      "acc 28 15 16 19\n",
      "AVG accuracy 0.0\n",
      "Epoch 1 completed\n",
      "acc 0 0 4 4\n",
      "acc 5 9 11 14\n",
      "acc 0 5 34 38\n",
      "acc 21 9 52 54\n",
      "acc 28 7 40 47\n",
      "AVG accuracy 0.0\n",
      "acc 0 8 41 45\n",
      "acc 0 11 8 10\n",
      "acc 0 9 66 72\n",
      "acc 0 10 5 10\n",
      "acc 44 19 36 37\n",
      "AVG accuracy 0.221176470588\n",
      "acc 0 10 41 44\n",
      "acc 0 11 29 29\n",
      "acc 0 8 2 7\n",
      "acc 0 2 10 12\n",
      "acc 0 4 59 61\n",
      "AVG accuracy 0.16\n",
      "acc 7 0 0 4\n",
      "acc 0 8 0 2\n",
      "acc 0 15 8 11\n",
      "acc 5 38 14 15\n",
      "acc 0 7 5 9\n",
      "AVG accuracy 0.29452991453\n",
      "acc 3 4 57 58\n",
      "acc 3 8 30 33\n",
      "acc 0 0 63 63\n",
      "acc 3 6 21 21\n",
      "acc 0 8 8 13\n",
      "AVG accuracy 0.0266666666667\n",
      "acc 3 2 11 13\n",
      "acc 0 0 43 45\n",
      "acc 38 11 55 55\n",
      "acc 13 10 45 48\n",
      "acc 0 24 59 59\n",
      "AVG accuracy 0.0\n",
      "acc 5 4 37 39\n",
      "acc 21 7 0 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc 5 0 44 47\n",
      "acc 0 8 17 22\n",
      "acc 7 9 0 1\n",
      "AVG accuracy 0.0\n",
      "acc 5 28 19 21\n",
      "acc 49 7 42 47\n",
      "acc 5 28 18 27\n",
      "acc 24 7 40 41\n",
      "acc 45 9 21 21\n",
      "AVG accuracy 0.162091503268\n",
      "acc 0 3 46 51\n",
      "acc 8 9 40 45\n",
      "acc 53 2 30 30\n",
      "acc 8 1 13 23\n",
      "acc 0 14 54 54\n",
      "AVG accuracy 0.0\n",
      "acc 0 8 63 63\n",
      "acc 0 7 1 3\n",
      "acc 0 60 26 30\n",
      "acc 2 2 27 29\n",
      "acc 3 0 24 24\n",
      "AVG accuracy 0.139393939394\n",
      "acc 28 47 20 21\n",
      "acc 0 60 67 68\n",
      "acc 65 2 16 22\n",
      "acc 0 23 0 4\n",
      "acc 0 60 0 0\n",
      "AVG accuracy 0.0754171301446\n",
      "acc 0 71 50 51\n",
      "acc 9 5 48 61\n",
      "acc 0 9 77 77\n",
      "acc 0 2 31 34\n",
      "acc 0 27 14 15\n",
      "AVG accuracy 0.0374774774775\n",
      "acc 3 42 17 20\n",
      "acc 0 9 60 62\n",
      "acc 0 33 31 41\n",
      "acc 0 8 14 17\n",
      "acc 0 14 7 11\n",
      "AVG accuracy 0.16303030303\n",
      "acc 0 5 57 58\n",
      "acc 41 32 10 12\n",
      "acc 0 24 50 53\n",
      "acc 7 7 23 29\n",
      "acc 0 0 48 50\n",
      "AVG accuracy 0.0\n",
      "acc 0 33 39 44\n",
      "acc 7 4 56 58\n",
      "acc 0 0 10 11\n",
      "acc 18 47 50 60\n",
      "acc 0 26 55 61\n",
      "AVG accuracy 0.0\n",
      "acc 0 60 54 54\n",
      "acc 0 7 27 29\n",
      "acc 0 8 59 66\n",
      "acc 2 2 8 10\n",
      "acc 0 0 31 33\n",
      "AVG accuracy 0.00645161290323\n",
      "acc 0 2 11 13\n",
      "acc 0 9 24 25\n",
      "acc 8 1 30 32\n",
      "acc 0 16 25 29\n",
      "acc 0 8 36 39\n",
      "AVG accuracy 0.0\n",
      "acc 3 0 76 77\n",
      "acc 1 11 64 67\n",
      "acc 25 6 3 6\n",
      "acc 0 9 3 5\n",
      "acc 7 2 54 60\n",
      "AVG accuracy 0.0923076923077\n",
      "acc 38 23 33 35\n",
      "acc 0 8 46 49\n",
      "acc 0 9 39 45\n",
      "acc 0 6 71 73\n",
      "acc 0 14 16 16\n",
      "AVG accuracy 0.0\n",
      "acc 0 9 14 15\n",
      "acc 21 7 36 39\n",
      "acc 0 1 33 35\n",
      "acc 8 2 10 18\n",
      "acc 37 8 53 55\n",
      "AVG accuracy 0.0\n",
      "acc 21 7 19 24\n",
      "acc 0 9 27 30\n",
      "acc 0 2 63 64\n",
      "acc 9 8 6 12\n",
      "acc 22 17 13 14\n",
      "AVG accuracy 0.0\n",
      "acc 0 7 30 30\n",
      "acc 53 49 71 77\n",
      "acc 55 44 18 20\n",
      "acc 0 6 19 19\n",
      "acc 9 2 26 26\n",
      "AVG accuracy 0.0\n",
      "acc 21 7 7 12\n",
      "acc 6 2 9 11\n",
      "acc 8 9 10 10\n",
      "acc 0 9 2 2\n",
      "acc 0 9 0 3\n",
      "AVG accuracy 0.150649350649\n",
      "acc 2 19 47 50\n",
      "acc 14 2 67 70\n",
      "acc 0 27 20 23\n",
      "acc 0 2 47 49\n",
      "acc 14 19 58 59\n",
      "AVG accuracy 0.05\n",
      "acc 0 8 25 26\n",
      "acc 8 59 52 54\n",
      "acc 0 56 2 10\n",
      "acc 14 19 71 77\n",
      "acc 0 36 27 27\n",
      "AVG accuracy 0.0868899521531\n",
      "acc 0 54 56 60\n",
      "acc 0 0 0 3\n",
      "acc 0 9 2 9\n",
      "acc 0 10 14 16\n",
      "acc 0 10 36 41\n",
      "AVG accuracy 0.257777777778\n",
      "acc 0 37 37 39\n",
      "acc 7 47 10 12\n",
      "acc 14 7 36 38\n",
      "acc 3 5 62 63\n",
      "acc 0 9 10 12\n",
      "AVG accuracy 0.0370288248337\n",
      "acc 0 3 35 37\n",
      "acc 53 47 65 71\n",
      "acc 0 48 27 29\n",
      "acc 0 28 32 34\n",
      "acc 0 36 28 31\n",
      "AVG accuracy 0.0621013133208\n",
      "acc 0 4 30 36\n",
      "acc 0 59 5 9\n",
      "acc 2 5 11 17\n",
      "acc 8 11 26 28\n",
      "acc 2 2 68 73\n",
      "AVG accuracy 0.0307692307692\n",
      "acc 8 2 62 63\n",
      "acc 48 9 10 11\n",
      "acc 0 59 29 29\n",
      "acc 4 10 76 78\n",
      "acc 0 0 4 4\n",
      "AVG accuracy 0.00655737704918\n",
      "acc 19 9 8 9\n",
      "acc 43 19 0 2\n",
      "acc 14 19 2 2\n",
      "acc 11 13 30 37\n",
      "acc 0 24 25 28\n",
      "AVG accuracy 0.0\n",
      "acc 5 9 6 6\n",
      "acc 0 9 72 74\n",
      "acc 4 2 14 18\n",
      "acc 0 20 65 67\n",
      "acc 0 8 12 20\n",
      "AVG accuracy 0.0666666666667\n",
      "acc 0 9 21 23\n",
      "acc 2 5 7 8\n",
      "acc 0 63 0 0\n",
      "acc 0 21 40 41\n",
      "acc 0 8 23 27\n",
      "AVG accuracy 0.00615384615385\n",
      "Epoch 3 completed\n",
      "acc 0 36 1 3\n",
      "acc 0 33 72 74\n",
      "acc 0 11 0 1\n",
      "acc 0 7 27 27\n",
      "acc 11 7 68 70\n",
      "AVG accuracy 0.0871428571429\n",
      "acc 2 32 9 15\n",
      "acc 0 10 56 57\n",
      "acc 0 5 10 15\n",
      "acc 19 9 68 71\n",
      "acc 0 0 16 20\n",
      "AVG accuracy 0.0736842105263\n",
      "acc 0 8 0 2\n",
      "acc 2 5 1 1\n",
      "acc 0 51 3 5\n",
      "acc 0 5 13 13\n",
      "acc 0 9 67 69\n",
      "AVG accuracy 0.121818181818\n",
      "acc 14 19 41 42\n",
      "acc 8 10 41 43\n",
      "acc 0 9 11 13\n",
      "acc 0 9 25 28\n",
      "acc 0 9 46 47\n",
      "AVG accuracy 0.0\n",
      "acc 38 23 56 58\n",
      "acc 0 2 31 35\n",
      "acc 16 11 6 7\n",
      "acc 8 1 57 58\n",
      "acc 0 2 57 59\n",
      "AVG accuracy 0.0\n",
      "acc 0 2 46 50\n",
      "acc 0 9 18 18\n",
      "acc 0 8 50 54\n",
      "acc 0 20 1 6\n",
      "acc 8 24 13 16\n",
      "AVG accuracy 0.165079365079\n",
      "acc 19 19 37 40\n",
      "acc 0 0 7 7\n",
      "acc 0 2 7 9\n",
      "acc 0 8 24 26\n",
      "acc 0 8 0 2\n",
      "AVG accuracy 0.1\n",
      "acc 1 44 29 29\n",
      "acc 0 2 4 9\n",
      "acc 25 2 3 6\n",
      "acc 0 8 13 20\n",
      "acc 11 2 15 17\n",
      "AVG accuracy 0.00888888888889\n",
      "acc 0 8 19 22\n",
      "acc 0 8 54 55\n",
      "acc 0 14 78 78\n",
      "acc 0 1 48 50\n",
      "acc 0 54 17 18\n",
      "AVG accuracy 0.0140350877193\n",
      "acc 0 30 27 28\n",
      "acc 0 54 40 43\n",
      "acc 0 51 24 24\n",
      "acc 8 1 0 1\n",
      "acc 0 9 67 70\n",
      "AVG accuracy 0.0589082381215\n",
      "acc 15 9 26 33\n",
      "acc 48 16 15 22\n",
      "acc 0 60 2 2\n",
      "acc 56 54 7 7\n",
      "acc 5 2 13 17\n",
      "AVG accuracy 0.00645161290323\n",
      "acc 0 24 4 5\n",
      "acc 0 59 7 8\n",
      "acc 3 18 7 15\n",
      "acc 44 51 54 58\n",
      "acc 7 4 37 39\n",
      "AVG accuracy 0.186532855436\n",
      "acc 0 2 5 9\n",
      "acc 0 2 40 42\n",
      "acc 0 33 18 21\n",
      "acc 0 8 13 20\n",
      "acc 0 32 12 14\n",
      "AVG accuracy 0.0754385964912\n",
      "acc 0 33 0 0\n",
      "acc 27 8 0 0\n",
      "acc 0 59 14 16\n",
      "acc 0 2 69 69\n",
      "acc 0 42 17 18\n",
      "AVG accuracy 0.048253968254\n",
      "acc 3 5 71 73\n",
      "acc 0 8 14 17\n",
      "acc 0 0 15 17\n",
      "acc 9 8 30 31\n",
      "acc 0 36 65 68\n",
      "AVG accuracy 0.0\n",
      "acc 32 24 23 25\n",
      "acc 28 78 37 44\n",
      "acc 0 14 29 33\n",
      "acc 0 8 54 56\n",
      "acc 14 5 13 14\n",
      "AVG accuracy 0.0542372881356\n",
      "acc 0 2 70 74\n",
      "acc 0 8 68 69\n",
      "acc 0 18 16 17\n",
      "acc 0 18 38 41\n",
      "acc 0 2 74 75\n",
      "AVG accuracy 0.0380952380952\n",
      "acc 9 5 34 37\n",
      "acc 18 28 42 44\n",
      "acc 0 24 23 24\n",
      "acc 0 11 0 1\n",
      "acc 8 17 66 73\n",
      "AVG accuracy 0.0867724867725\n",
      "acc 0 51 3 9\n",
      "acc 8 10 28 30\n",
      "acc 0 8 39 44\n",
      "acc 0 33 29 29\n",
      "acc 0 9 1 3\n",
      "AVG accuracy 0.151193890855\n",
      "acc 8 26 71 75\n",
      "acc 27 8 46 49\n",
      "acc 3 18 19 24\n",
      "acc 3 5 1 1\n",
      "acc 0 1 14 16\n",
      "AVG accuracy 0.0\n",
      "acc 28 9 11 11\n",
      "acc 0 41 44 47\n",
      "acc 0 18 38 42\n",
      "acc 0 17 0 2\n",
      "acc 0 0 32 32\n",
      "AVG accuracy 0.0571428571429\n",
      "acc 0 1 16 17\n",
      "acc 40 3 23 28\n",
      "acc 34 41 31 32\n",
      "acc 8 5 58 61\n",
      "acc 0 0 21 22\n",
      "AVG accuracy 0.0\n",
      "acc 2 2 68 74\n",
      "acc 0 0 10 15\n",
      "acc 0 1 28 33\n",
      "acc 0 14 73 73\n",
      "acc 0 2 59 60\n",
      "AVG accuracy 0.0\n",
      "acc 8 48 59 65\n",
      "acc 0 2 10 14\n",
      "acc 8 2 19 21\n",
      "acc 0 28 4 5\n",
      "acc 0 8 3 5\n",
      "AVG accuracy 0.125806451613\n",
      "acc 0 27 20 21\n",
      "acc 0 17 13 14\n",
      "acc 0 17 5 10\n",
      "acc 0 11 63 67\n",
      "acc 18 25 34 36\n",
      "AVG accuracy 0.166666666667\n",
      "acc 0 6 60 66\n",
      "acc 0 0 63 65\n",
      "acc 2 2 8 8\n",
      "acc 0 2 8 14\n",
      "acc 0 11 39 40\n",
      "AVG accuracy 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-3f2c029e9131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0mtrainStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'completed'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3f2c029e9131>\u001b[0m in \u001b[0;36mtrainStep\u001b[0;34m(step)\u001b[0m\n\u001b[1;32m     26\u001b[0m     _,loss, stat = sess.run(\n\u001b[1;32m     27\u001b[0m         \u001b[0;34m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msum_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mquestion_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mque_v\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_ph\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdoc_v\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_end_true\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstart_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_true\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     )\n\u001b[1;32m     30\u001b[0m     \u001b[0;31m#if step % 15 == 0 : print(step, loss, start_true, end_true)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#=========== Training ==================\n",
    "\n",
    "\n",
    "def accuracyValidation(acc_batch_size, step):\n",
    "    acc_accum = 0\n",
    "    for step_accuracy_ in range(acc_batch_size):\n",
    "        start_true, end_true, doc, que, doc_v, que_v = sess.run(next_element_valid)\n",
    "        acc, stat, s, e = sess.run(\n",
    "            (accuracy, summary_op, pr_start_idx, pr_end_idx),\n",
    "            feed_dict={question_ph: [que_v], document_ph: [doc_v], start_end_true: [start_true, end_true]}\n",
    "        )\n",
    "        #print('Predicted answer', utils.substr(doc, s, e))\n",
    "        #print('True answer', utils.substr(doc, start_true, end_true))\n",
    "        writer.add_summary(stat,  step* 10 + step_accuracy_)\n",
    "        #print(\"acc\", s, e, start_true, end_true)\n",
    "        acc_accum += acc;\n",
    "    print('AVG accuracy', acc_accum/acc_batch_size)\n",
    "\n",
    "def trainStep(step):\n",
    "    start_true, end_true, doc, que, doc_v, que_v = sess.run(next_element)\n",
    "    \n",
    "    if start_true < 0 or end_true > max_sequence_length - 1: \n",
    "        print('Ignore step', start_true, end_true)\n",
    "        return\n",
    "    \n",
    "    _,loss, stat = sess.run(\n",
    "        (train_step, sum_loss, summary_op), \n",
    "        feed_dict={question_ph: [que_v], document_ph: [doc_v], start_end_true: [start_true, end_true]}\n",
    "    )\n",
    "    #if step % 15 == 0 : print(step, loss, start_true, end_true)\n",
    "    writer.add_summary(stat,  step)\n",
    "\n",
    "\n",
    "dataset = ds.getDataset([\"./train_train_task_b.csv\"], max_sequence_length)\n",
    "#iterator = dataset.make_one_shot_iterator()\n",
    "#next_element = iterator.get_next()\n",
    "\n",
    "dataset_validation = ds.getDataset([\"./valid_train_task_b.csv\"], max_sequence_length)\n",
    "iterator_valid = dataset_validation.make_one_shot_iterator()\n",
    "next_element_valid = iterator_valid.get_next()\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(FLAGS.log_path + \"/9\", sess.graph)\n",
    "    for epoch_ in range(max_epoch):\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        next_element = iterator.get_next()\n",
    "        #iterator_valid = dataset_validation.make_one_shot_iterator()\n",
    "        #next_element_valid = iterator_valid.get_next()\n",
    "        for step_ in range(2000):\n",
    "            if step_ > 0 and step_ % 50 == 0:\n",
    "                # --------- ACCURACY -------------\n",
    "                accuracyValidation(acc_batch_size, step_)\n",
    "  \n",
    "            else:\n",
    "                trainStep(step_)\n",
    "                \n",
    "        print('Epoch', epoch_, 'completed')\n",
    "    print('End')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
