{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import maxout\n",
    "import highway_maxout as hmn\n",
    "import utils\n",
    "import dataset as ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======= FLAGS ==========\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('maxout_layer_size', 10, 'Maxout layer size')\n",
    "tf.app.flags.DEFINE_integer('maxout_pooling_size', 4, 'Maxout pooling size')\n",
    "tf.app.flags.DEFINE_integer('lstm_size', 11, 'LSTM cell internal size')\n",
    "tf.app.flags.DEFINE_string('log_path', '/tmp/dcn', 'logs location')\n",
    "tf.app.flags.DEFINE_integer('acc_batch_size', 5, 'How many examples to use to calculate accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all variables\n",
    "#tf.reset_default_graph();\n",
    "\n",
    "lstm_size = FLAGS.lstm_size\n",
    "acc_batch_size = FLAGS.acc_batch_size\n",
    "word_vector_size = 300\n",
    "maxout_pooling_size = FLAGS.maxout_pooling_size\n",
    "max_decoder_iterations = 4\n",
    "maxout_layer_size = FLAGS.maxout_layer_size;\n",
    "max_epoch = 1000;\n",
    "max_sequence_length = 80\n",
    "#training_set_size = 100;\n",
    "\n",
    "# \n",
    "question_ph = tf.placeholder(tf.float32, [1, max_sequence_length, word_vector_size], name=\"q_input\")\n",
    "document_ph = tf.placeholder(tf.float32, [1, max_sequence_length, word_vector_size], name=\"d_input\")\n",
    "\n",
    "doc_len_ph = tf.placeholder(tf.int32, ())\n",
    "que_len_ph = tf.placeholder(tf.int32, ())\n",
    "\n",
    "with tf.name_scope('ENCODER'):\n",
    "    # LSTM cell initialization\n",
    "    lstm = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm = tf.nn.rnn_cell.DropoutWrapper(cell=lstm, output_keep_prob=0.5)\n",
    "\n",
    "\n",
    "# LSTM cells for Bi-LSTM for COATINATION ENCODER\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_fw, output_keep_prob=0.5)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_bw, output_keep_prob=0.5)\n",
    "\n",
    "# create lstm cell for DYNAMIC POINTING DECODER\n",
    "lstm_dec = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# get lstm initial state of zeroes\n",
    "#lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "start_pos = 0; # ?generate random between (0, document_size-1)\n",
    "end_pos = 0;   # ?generate random between (0, document_size-1)\n",
    "\n",
    "# create sentinel vector variable for both encodings \n",
    "#with tf.variable_scope(\"scope1\") as scope:\n",
    "sentinel_q = tf.get_variable(\"sentinel_q\", [ lstm_size , 1], initializer = tf.random_normal_initializer())\n",
    "sentinel_d = tf.get_variable(\"sentinel_d\", [ lstm_size , 1], initializer = tf.random_normal_initializer()) \n",
    "\n",
    "tf.summary.histogram('sentinel_q', sentinel_q)\n",
    "tf.summary.histogram('sentinel_q_max', tf.reduce_max(sentinel_q))\n",
    "tf.summary.histogram('sentinel_d', sentinel_d)\n",
    "tf.summary.histogram('sentinel_d_max', tf.reduce_max(sentinel_d))\n",
    "\n",
    "# optimizer\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Slice_1:0\", shape=(?, ?), dtype=float32)\n",
      "Tensor(\"COATTENTION_ENCODER_1/strided_slice:0\", shape=(?, 22), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'U_max:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# def length(sequence):\n",
    "#   used = tf.sign(tf.reduce_max(tf.abs(sequence), 2))\n",
    "#   length = tf.reduce_sum(used, 1)\n",
    "#   length = tf.cast(length, tf.int32)\n",
    "#   return length\n",
    "\n",
    "'''\n",
    "transform tensor of shape [1, question_size, word_vector_size] to list of tensors of shape [1, word_vector_size]\n",
    "of length question_size. first dimenstion is batch size = 1\n",
    "'''\n",
    "\n",
    "#print(tf.shape(question_ph)[1])\n",
    "#question_input = tf.unstack(question_ph, max_sequence_length, 1)\n",
    "#document_input = tf.unstack(document_ph, max_sequence_length, 1)\n",
    "#print(x)\n",
    "\n",
    "# we use the same LSTM for both encodings to share weights\n",
    "with tf.name_scope('ENCODER'):\n",
    "    with tf.name_scope('Q_ENC'):\n",
    "        outputs_q, state_q = tf.nn.dynamic_rnn(lstm, inputs = question_ph, sequence_length = [que_len_ph], dtype=tf.float32)\n",
    "    with tf.name_scope('D_ENC'):\n",
    "        outputs_d, state_d = tf.nn.dynamic_rnn(lstm, inputs = document_ph, sequence_length = [doc_len_ph], dtype=tf.float32)\n",
    "\n",
    "\n",
    "document_size = doc_len_ph\n",
    "question_size = que_len_ph\n",
    "doc_padding = tf.subtract([0, max_sequence_length], [0, document_size])\n",
    "que_padding = tf.subtract([0, max_sequence_length], [0, question_size])\n",
    "\n",
    "\n",
    "# \"squeeze\" transforms list of tensors of shape [1, lstm_size] of length L to tensor of shape [L, lstm_size]\n",
    "que_enc = tf.transpose(tf.squeeze(outputs_q))\n",
    "que_enc = tf.slice(que_enc, [0,0], [lstm_size, question_size])\n",
    "que_enc_sentinel = tf.concat([que_enc, sentinel_q], axis = 1)\n",
    "que_enc_sentinel = tf.pad(que_enc_sentinel, [[0,0], que_padding])\n",
    "que_enc_sentinel.set_shape([lstm_size, max_sequence_length + 1])\n",
    "que_enc_sentinel = utils.non_linear_projection(que_enc_sentinel)\n",
    "que_enc_sentinel = tf.slice(que_enc_sentinel, [0,0], [lstm_size, question_size + 1])\n",
    "#que_enc_sentinel.set_shape([lstm_size, max_sequence_length + 1])\n",
    "\n",
    "doc_enc = tf.transpose(tf.squeeze(outputs_d))\n",
    "doc_enc = tf.slice(doc_enc, [0,0], [lstm_size, document_size])\n",
    "#doc_enc = tf.pad(doc_enc, [[0,0], doc_padding])\n",
    "#doc_enc.set_shape([lstm_size, max_sequence_length])\n",
    "\n",
    "\n",
    "tf.summary.histogram('QUE_enc', que_enc)\n",
    "tf.summary.histogram('DOC_enc', doc_enc)\n",
    "tf.summary.histogram('DOC_enc_max', tf.reduce_max(doc_enc))\n",
    "tf.summary.histogram('QUE_enc_max', tf.reduce_max(que_enc))\n",
    "tf.summary.histogram('Document_size', document_size)\n",
    "tf.summary.histogram('Question_size', question_size)\n",
    "\n",
    "\n",
    "# append sentinel vector for both encodings \n",
    "doc_enc_sentinel = tf.concat([doc_enc, sentinel_d], axis = 1)\n",
    "#que_enc_sentinel = utils.non_linear_projection(tf.concat([que_enc, sentinel_q], axis = 1))\n",
    "print(que_enc_sentinel)\n",
    "#que_enc_sentinel = tf.slice(que_enc_sentinel, [0,0], [lstm_size, question_size + 1])\n",
    "\n",
    "# ===================  COATTENTION ENCODER ===================\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    # L \\in R(doc_size + 1) x (que_size + 1)\n",
    "    L = tf.matmul(doc_enc_sentinel, que_enc_sentinel, transpose_a = True)\n",
    "    A_Q = tf.nn.softmax(L, 1)\n",
    "    A_D = tf.nn.softmax(tf.transpose(L), 1)\n",
    "    C_Q = tf.matmul(doc_enc_sentinel, A_Q)\n",
    "    # C_D \\in R_2*lstm_size x (doc_size + 1)\n",
    "    C_D = tf.matmul(tf.concat([que_enc_sentinel, C_Q], axis = 0), A_D)\n",
    "\n",
    "    # bi_lstm_input = tf.unstack(tf.reshape(tf.transpose(tf.concat([doc_enc_sentinel, C_D], axis = 0)), [max_sequence_length + 1, 1, 3*lstm_size]))\n",
    "    # TODO Q: would we use single cell of two different\n",
    "    bi_lstm_input = tf.concat([doc_enc_sentinel, C_D], axis = 0)\n",
    "    bi_lstm_input = tf.transpose(bi_lstm_input)\n",
    "    bi_lstm_input = tf.reshape(bi_lstm_input, [1, document_size + 1, 3*lstm_size])\n",
    "    \n",
    "    tf.summary.histogram('bi_lstm_input', bi_lstm_input)\n",
    "    \n",
    "    outputs_bi, output_state = tf.nn.bidirectional_dynamic_rnn(\n",
    "        cell_fw = lstm_cenc_fw, \n",
    "        cell_bw = lstm_cenc_bw,\n",
    "      #  cell_bw = lstm_cenc_bw,\n",
    "        inputs = bi_lstm_input,\n",
    "       # sequence_length = [document_size[0] + 1],\n",
    "        dtype=tf.float32\n",
    "    )\n",
    "\n",
    "    # we take first because of we feed to bi-RNN only one sentence\n",
    "    outputs_bi = tf.concat(outputs_bi, axis=2)[0]\n",
    "    print(outputs_bi)\n",
    "    U = tf.slice(outputs_bi, [0,0], [document_size, 2*lstm_size])\n",
    "    U = tf.transpose(U)\n",
    "#print(U)\n",
    "tf.summary.histogram('U', U)\n",
    "tf.summary.histogram('U_max', tf.reduce_max(U))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<unknown>\n"
     ]
    }
   ],
   "source": [
    "# ===================== DYNAMIC POINTING DECODER =============\n",
    "\n",
    "\n",
    "#scope = tf.get_variable_scope()\n",
    "#u_t = get_scope_variable(scope, 'hmn_u_t', [2*lstm_size, 1]) \n",
    "#h_i = get_scope_variable(scope, 'hmn_h_i', [lstm_size, 1 ]) \n",
    "#u_s_i = get_scope_variable(scope, 'hmn_u_s_i', [2*lstm_size, 1])\n",
    "#u_e_i = get_scope_variable(scope, 'hmn_u_e_i', [2*lstm_size, 1])\n",
    "\n",
    "\n",
    "#m_3 = HMN(U, h_i, u_s_i, u_e_i)\n",
    "#print(m_3)\n",
    "\n",
    "# returns tuple (scores_start, scores_end, strart_pos, start_end, new_lstm_state)\n",
    "def decoderIteration(U, lstm_state, start_pos, end_pos, iter_number):\n",
    "    with tf.name_scope('Decoder_Iteration'):\n",
    "        with tf.name_scope('Next_Start'):\n",
    "            scores_start = hmn.HMN(U, \n",
    "                               tf.transpose(lstm_state.h), \n",
    "                               tf.slice(U, [0, start_pos], [lstm_size*2, 1]) ,\n",
    "                               tf.slice(U, [0, end_pos], [lstm_size*2, 1]) , \n",
    "                               document_size,\n",
    "                               'start',\n",
    "                                FLAGS,\n",
    "                                iter_number)\n",
    "\n",
    "            new_start_pos = tf.to_int32(tf.argmax(scores_start, 0))\n",
    "\n",
    "        #print(lstm_state)\n",
    "        with tf.name_scope('Next_End'):\n",
    "            scores_end = hmn.HMN(U, \n",
    "                             tf.transpose(lstm_state.h), \n",
    "                             tf.slice(U, [0, new_start_pos], [lstm_size*2, 1],) ,\n",
    "                             tf.slice(U, [0, end_pos], [lstm_size*2, 1]), \n",
    "                             document_size,\n",
    "                            'end',\n",
    "                            FLAGS,\n",
    "                            iter_number)\n",
    "            new_end_pos = tf.to_int32(tf.argmax(scores_end, 0))\n",
    "        \n",
    "        with tf.name_scope('LSTM_State_Update'):\n",
    "            lstm_input = tf.concat(\n",
    "                [tf.slice(U, [0, new_start_pos], [lstm_size*2, 1], name='slice-5'), tf.slice(U, [0, new_end_pos], [lstm_size*2, 1])],\n",
    "                axis = 0\n",
    "            )\n",
    "            output, new_lstm_state = lstm_dec(tf.reshape(lstm_input, [1, lstm_size*4]), lstm_state)\n",
    "        \n",
    "        #print(new_lstm_state)\n",
    "        return scores_start, scores_end, new_start_pos , new_end_pos, new_lstm_state\n",
    "\n",
    "\n",
    "\n",
    "#print(lstm_dec_state)\n",
    "\n",
    "with tf.name_scope('DYNAMIC_POINTING_DECODER'):\n",
    "    \n",
    "    start_pos = 0;\n",
    "    end_pos = 0;\n",
    "    sum_start_scores = tf.zeros([1, document_size])\n",
    "    sum_end_scores = tf.zeros([1, document_size])\n",
    "    lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "    \n",
    "    for step in range(max_decoder_iterations):\n",
    "        scores_start, scores_end, new_start_pos, new_end_pos, lstm_dec_state = decoderIteration(U, lstm_dec_state, start_pos, end_pos, step + 1)\n",
    "        sum_start_scores = tf.add(sum_start_scores, scores_start)\n",
    "        sum_end_scores   = tf.add(sum_end_scores, scores_end)\n",
    "        if new_start_pos == start_pos and end_pos == new_end_pos : break\n",
    "        start_pos = new_start_pos\n",
    "        end_pos = new_end_pos\n",
    "\n",
    "    \n",
    "# loss and train step\n",
    "start_end_true = tf.placeholder(tf.int32, [2]);\n",
    "#end_true = tf.placeholder(tf.int32, ());\n",
    "onehot_labels = tf.one_hot(start_end_true, document_size)\n",
    "with tf.name_scope('Loss'):\n",
    "    sum_loss = tf.losses.softmax_cross_entropy(\n",
    "        onehot_labels,\n",
    "        tf.concat([sum_start_scores, sum_end_scores], axis=0))\n",
    "\n",
    "\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    with tf.name_scope('Prediction'):\n",
    "        pr_start_idx = tf.to_int32(tf.argmax(sum_start_scores, 1))[0]\n",
    "        pr_end_idx = tf.to_int32(tf.argmax(sum_end_scores, 1))[0]\n",
    "    with tf.name_scope('Accuracy'):\n",
    "        accuracy = tf.py_func(utils.f1_score_int, [pr_start_idx, pr_end_idx, start_end_true[0], start_end_true[1]], tf.float64)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "    \n",
    "print(sum_start_scores.get_shape())    \n",
    "    \n",
    "tf.summary.scalar('loss', sum_loss)\n",
    "with tf.name_scope('Train'):\n",
    "    train_step = optimizer.minimize(sum_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4.75768 24 24\n",
      "25 5.25153 21 25\n",
      "AVG accuracy 0.0\n",
      "75 4.29911 22 25\n",
      "Epoch 0 completed\n",
      "0 4.37216 24 24\n",
      "25 5.17323 21 25\n",
      "AVG accuracy 0.0\n",
      "75 4.1994 22 25\n",
      "Epoch 1 completed\n",
      "0 4.18683 24 24\n",
      "25 4.984 21 25\n",
      "AVG accuracy 0.0\n",
      "75 4.23976 22 25\n",
      "Epoch 2 completed\n",
      "0 4.1 24 24\n",
      "25 4.95828 21 25\n",
      "AVG accuracy 0.048\n",
      "75 4.024 22 25\n",
      "Epoch 3 completed\n",
      "0 3.55829 24 24\n",
      "25 4.53543 21 25\n",
      "AVG accuracy 0.108333333333\n",
      "75 3.9895 22 25\n",
      "Epoch 4 completed\n",
      "0 3.78722 24 24\n",
      "25 4.17235 21 25\n",
      "AVG accuracy 0.00888888888889\n",
      "75 3.83935 22 25\n",
      "Epoch 5 completed\n",
      "0 3.95966 24 24\n",
      "25 3.892 21 25\n",
      "AVG accuracy 0.059272404614\n",
      "75 4.01274 22 25\n",
      "Epoch 6 completed\n",
      "0 3.51241 24 24\n",
      "25 3.67866 21 25\n",
      "AVG accuracy 0.11\n",
      "75 3.60257 22 25\n",
      "Epoch 7 completed\n",
      "0 3.60775 24 24\n",
      "25 3.81336 21 25\n",
      "AVG accuracy 0.0\n",
      "75 3.41838 22 25\n",
      "Epoch 8 completed\n",
      "0 3.65118 24 24\n",
      "25 3.51044 21 25\n",
      "AVG accuracy 0.00588235294118\n",
      "75 3.27279 22 25\n",
      "Epoch 9 completed\n",
      "0 3.34851 24 24\n",
      "25 3.1932 21 25\n",
      "AVG accuracy 0.0463768115942\n",
      "75 3.25164 22 25\n",
      "Epoch 10 completed\n",
      "0 3.67326 24 24\n",
      "25 3.06895 21 25\n",
      "AVG accuracy 0.104807692308\n",
      "75 2.65609 22 25\n",
      "Epoch 11 completed\n",
      "0 2.78362 24 24\n",
      "25 3.30444 21 25\n",
      "AVG accuracy 0.0597140454163\n",
      "75 2.9144 22 25\n",
      "Epoch 12 completed\n",
      "0 3.48087 24 24\n",
      "25 2.90911 21 25\n",
      "AVG accuracy 0.0\n",
      "75 2.75123 22 25\n",
      "Epoch 13 completed\n",
      "0 2.39007 24 24\n",
      "25 2.86611 21 25\n",
      "AVG accuracy 0.038208168643\n",
      "75 3.09865 22 25\n",
      "Epoch 14 completed\n",
      "0 2.06221 24 24\n",
      "25 3.17293 21 25\n",
      "AVG accuracy 0.116666666667\n",
      "75 2.24695 22 25\n",
      "Epoch 15 completed\n",
      "0 1.83793 24 24\n",
      "25 3.12918 21 25\n",
      "AVG accuracy 0.114285714286\n",
      "75 1.83984 22 25\n",
      "Epoch 16 completed\n",
      "0 1.87418 24 24\n",
      "25 2.72342 21 25\n",
      "AVG accuracy 0.104891165173\n",
      "75 2.49549 22 25\n",
      "Epoch 17 completed\n",
      "0 1.22277 24 24\n",
      "25 1.94596 21 25\n",
      "AVG accuracy 0.0\n",
      "75 1.57931 22 25\n",
      "Epoch 18 completed\n",
      "0 2.12031 24 24\n",
      "25 2.25764 21 25\n",
      "AVG accuracy 0.0866666666667\n",
      "75 1.54828 22 25\n",
      "Epoch 19 completed\n",
      "0 2.79421 24 24\n",
      "25 1.48726 21 25\n",
      "AVG accuracy 0.05\n",
      "75 1.86938 22 25\n",
      "Epoch 20 completed\n",
      "0 1.91691 24 24\n",
      "25 1.40341 21 25\n",
      "AVG accuracy 0.0\n",
      "75 1.28214 22 25\n",
      "Epoch 21 completed\n",
      "0 0.253748 24 24\n",
      "25 1.30983 21 25\n",
      "AVG accuracy 0.0115942028986\n",
      "75 1.43518 22 25\n",
      "Epoch 22 completed\n",
      "0 0.818284 24 24\n",
      "25 1.11985 21 25\n",
      "AVG accuracy 0.0\n",
      "75 1.04979 22 25\n",
      "Epoch 23 completed\n",
      "0 0.863924 24 24\n",
      "25 1.08487 21 25\n",
      "AVG accuracy 0.0\n",
      "75 0.91724 22 25\n",
      "Epoch 24 completed\n",
      "0 0.841022 24 24\n",
      "25 1.48092 21 25\n",
      "AVG accuracy 0.0\n",
      "75 0.50743 22 25\n",
      "Epoch 25 completed\n",
      "0 0.4882 24 24\n",
      "25 0.690197 21 25\n",
      "AVG accuracy 0.0\n",
      "75 0.620498 22 25\n",
      "Epoch 26 completed\n",
      "0 0.617866 24 24\n",
      "25 0.223347 21 25\n",
      "AVG accuracy 0.0\n",
      "75 0.451343 22 25\n",
      "Epoch 27 completed\n",
      "0 0.996159 24 24\n",
      "25 0.658015 21 25\n",
      "AVG accuracy 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a19c13098ad0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m                 \u001b[0mtrainStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-a19c13098ad0>\u001b[0m in \u001b[0;36mtrainStep\u001b[0;34m(step)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrainStep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mstart_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mque\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_v\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mque_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstart_true\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mend_true\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmax_sequence_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Ignore step'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#=========== Training ==================\n",
    "\n",
    "\n",
    "def accuracyValidation(acc_batch_size, step):\n",
    "    acc_accum = 0\n",
    "    for step_accuracy_ in range(acc_batch_size):\n",
    "        start_true, end_true, doc, que, doc_v, que_v = sess.run(next_element_valid)\n",
    "        acc, stat, s, e = sess.run(\n",
    "            (accuracy, summary_op, pr_start_idx, pr_end_idx),\n",
    "            feed_dict={\n",
    "                question_ph: [que_v], \n",
    "                document_ph: [doc_v], \n",
    "                start_end_true: [start_true, end_true],\n",
    "                doc_len_ph: len(doc),\n",
    "                que_len_ph: len(que)\n",
    "            }\n",
    "        )\n",
    "        #print('Predicted answer', utils.substr(doc, s, e))\n",
    "        #print('True answer', utils.substr(doc, start_true, end_true))\n",
    "        writer.add_summary(stat,  step* 10 + step_accuracy_)\n",
    "        #print(\"acc\", s, e, start_true, end_true)\n",
    "        acc_accum += acc;\n",
    "    print('AVG accuracy', acc_accum/acc_batch_size)\n",
    "\n",
    "def trainStep(step):\n",
    "    start_true, end_true, doc, que, doc_v, que_v = sess.run(next_element)\n",
    "    if start_true < 0 or end_true > max_sequence_length - 1: \n",
    "        print('Ignore step', start_true, end_true)\n",
    "        return\n",
    "    \n",
    "    #print(len(doc), len(que))\n",
    "    _,loss, stat = sess.run(\n",
    "        (train_step, sum_loss, summary_op), \n",
    "        feed_dict={\n",
    "            question_ph: [que_v], \n",
    "            document_ph: [doc_v], \n",
    "            start_end_true: [start_true, end_true],\n",
    "            doc_len_ph: len(doc),\n",
    "            que_len_ph: len(que)\n",
    "        }\n",
    "    )\n",
    "    if step % 25 == 0 : print(step, loss, start_true, end_true)\n",
    "    writer.add_summary(stat,  step)\n",
    "\n",
    "\n",
    "dataset = ds.getDataset([\"./train_train_task_b.csv\"], max_sequence_length)\n",
    "#iterator = dataset.make_one_shot_iterator()\n",
    "#next_element = iterator.get_next()\n",
    "\n",
    "dataset_validation = ds.getDataset([\"./valid_train_task_b.csv\"], max_sequence_length)\n",
    "iterator_valid = dataset_validation.make_one_shot_iterator()\n",
    "next_element_valid = iterator_valid.get_next()\n",
    "\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    writer = tf.summary.FileWriter(FLAGS.log_path + \"/9\", sess.graph)\n",
    "    for epoch_ in range(max_epoch):\n",
    "        iterator = dataset.make_one_shot_iterator()\n",
    "        next_element = iterator.get_next()\n",
    "        #iterator_valid = dataset_validation.make_one_shot_iterator()\n",
    "        #next_element_valid = iterator_valid.get_next()\n",
    "        for step_ in range(100):\n",
    "            if step_ > 0 and step_ % 50 == 0:\n",
    "                # --------- ACCURACY -------------\n",
    "                accuracyValidation(acc_batch_size, step_)\n",
    "  \n",
    "            else:\n",
    "                trainStep(step_)\n",
    "                \n",
    "                \n",
    "        print('Epoch', epoch_, 'completed')\n",
    "    print('End')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
