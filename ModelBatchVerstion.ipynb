{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import maxout\n",
    "import highway_maxout as hmn\n",
    "import utils\n",
    "import encoder as enc\n",
    "import dataset as ds\n",
    "import train as tr\n",
    "import decoder as dec\n",
    "import time\n",
    "from itertools import islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#======= FLAGS ==========\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('maxout_layer_size', 200, 'Maxout layer size')\n",
    "tf.app.flags.DEFINE_integer('max_sequence_length', 160, 'Max length of context')\n",
    "tf.app.flags.DEFINE_integer('max_question_length', 40, 'Max question tokens length')\n",
    "tf.app.flags.DEFINE_float('learning_rate', 0.001, 'Learning Rate')\n",
    "tf.app.flags.DEFINE_integer('maxout_pooling_size', 8, 'Maxout pooling size')\n",
    "tf.app.flags.DEFINE_integer('lstm_size', 200, 'LSTM cell internal size')\n",
    "tf.app.flags.DEFINE_string('log_path', '/tmp/working/logs', 'logs location')\n",
    "tf.app.flags.DEFINE_integer('acc_batch_size', 10, 'How many examples to use to calculate accuracy')\n",
    "tf.app.flags.DEFINE_integer('train_batch_size', 10, 'Train Batch Size')\n",
    "tf.app.flags.DEFINE_integer('max_decoder_iterations', 4, 'Decoder Iterations')\n",
    "tf.app.flags.DEFINE_integer('max_epoch', 200, 'Max Train Epoch Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all variables\n",
    "#tf.reset_default_graph();\n",
    "\n",
    "lstm_size = FLAGS.lstm_size\n",
    "acc_batch_size = FLAGS.acc_batch_size\n",
    "word_vector_size = 300\n",
    "maxout_pooling_size = FLAGS.maxout_pooling_size\n",
    "max_decoder_iterations = FLAGS.max_decoder_iterations\n",
    "maxout_layer_size = FLAGS.maxout_layer_size;\n",
    "max_epoch = FLAGS.max_epoch;\n",
    "max_sequence_length = FLAGS.max_sequence_length;\n",
    "max_question_length = FLAGS.max_question_length\n",
    "batch_size = FLAGS.train_batch_size\n",
    "\n",
    "\n",
    "dropout_rate_ph = tf.placeholder(tf.float32)\n",
    "question_ph = tf.placeholder(tf.float32, [batch_size, max_question_length, word_vector_size], name=\"q_input\")\n",
    "document_ph = tf.placeholder(tf.float32, [batch_size, max_sequence_length, word_vector_size], name=\"d_input\")\n",
    "doc_len_ph = tf.placeholder(tf.int32, [batch_size])\n",
    "que_len_ph = tf.placeholder(tf.int32, [batch_size])\n",
    "document_size = doc_len_ph\n",
    "question_size = que_len_ph\n",
    "\n",
    "with tf.name_scope('ENCODER'):\n",
    "    # LSTM cell initialization\n",
    "    lstm = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm = tf.nn.rnn_cell.DropoutWrapper(cell=lstm, output_keep_prob=dropout_rate_ph)\n",
    "\n",
    "\n",
    "# LSTM cells for Bi-LSTM for COATINATION ENCODER\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_fw, output_keep_prob=dropout_rate_ph)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_bw, output_keep_prob=dropout_rate_ph)\n",
    "\n",
    "# create lstm cell for DYNAMIC POINTING DECODER\n",
    "lstm_dec = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# get lstm initial state of zeroes\n",
    "#lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "start_pos = 0; # ?generate random between (0, document_size-1)\n",
    "end_pos = 0;   # ?generate random between (0, document_size-1)\n",
    "\n",
    "# create sentinel vector variable for both encodings \n",
    "#with tf.variable_scope(\"scope1\") as scope:\n",
    "sentinel_q = tf.get_variable(\"sentinel_q\", [ 1, lstm_size ], initializer = tf.random_normal_initializer())\n",
    "sentinel_d = tf.get_variable(\"sentinel_d\", [ 1, lstm_size ], initializer = tf.random_normal_initializer()) \n",
    "\n",
    "tf.summary.histogram('sentinel_q', sentinel_q)\n",
    "tf.summary.histogram('sentinel_q_max', tf.reduce_max(sentinel_q))\n",
    "tf.summary.histogram('sentinel_d', sentinel_d)\n",
    "tf.summary.histogram('sentinel_d_max', tf.reduce_max(sentinel_d))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"COATTENTION_ENCODER_1/Slice_2:0\", shape=(10, 160, 400), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# (batch, D, 2L)\n",
    "U = enc.encoderBatch(\n",
    "    document_ph, question_ph, \n",
    "    document_size, question_size, \n",
    "    lstm, lstm_cenc_fw, lstm_cenc_bw, \n",
    "    sentinel_d, sentinel_q, \n",
    "    FLAGS)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== DYNAMIC POINTING DECODER =============\n",
    "\n",
    "sum_start_scores, sum_end_scores = dec.decoderBatch(U, lstm_dec, dropout_rate_ph, FLAGS)\n",
    "\n",
    "start_true = tf.placeholder(tf.int32, [batch_size]);\n",
    "end_true   = tf.placeholder(tf.int32, [batch_size]);\n",
    "    \n",
    "#sum_start_scores = tf.Print(sum_start_scores, [start_end_true, sum_start_scores], 'sum_start_scores: ')\n",
    "#sum_end_scores = tf.Print(sum_end_scores, [start_end_true, sum_end_scores], 'sum_start_scores: ')\n",
    "    \n",
    "    \n",
    "# loss and train step\n",
    "onehot_labels_start = tf.one_hot(start_true, max_sequence_length)\n",
    "onehot_labels_end   = tf.one_hot(end_true, max_sequence_length)\n",
    "#print(\"sum_start_scores\", sum_start_scores)\n",
    "with tf.name_scope('Loss'):\n",
    "    loss_start = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels = onehot_labels_start,\n",
    "        logits = sum_start_scores)\n",
    "    loss_start = tf.reduce_mean(loss_start)\n",
    "    loss_end = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels = onehot_labels_end,\n",
    "        logits = sum_end_scores)\n",
    "    loss_end = tf.reduce_mean(loss_end)\n",
    "    sum_loss = loss_start + loss_end\n",
    "\n",
    "\n",
    "tf.summary.histogram('sum_start_scores', sum_start_scores)\n",
    "tf.summary.histogram('sum_end_scores', sum_end_scores)\n",
    "tf.summary.scalar('loss_test', sum_loss, [\"TEST_STAT\"])\n",
    "tf.summary.scalar('loss_train', sum_loss, [\"TRAIN_STAT\"])\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    with tf.name_scope('Prediction'):\n",
    "        pr_start_idx = tf.to_int32(tf.argmax(sum_start_scores, 1))\n",
    "        pr_end_idx = tf.to_int32(tf.argmax(sum_end_scores, 1))\n",
    "         \n",
    "    with tf.name_scope('Accuracy'):\n",
    "        accuracy_avg = tf.py_func(utils.f1_score_int_avg, [pr_start_idx, pr_end_idx, start_true, end_true], tf.float64)\n",
    "        #accuracy_avg = tf.Print(accuracy_avg, [[start_true, end_true], [pr_start_idx, pr_end_idx], accuracy_avg], 'True and Predicted: ')\n",
    "\n",
    "\n",
    "#avg_accuracy_ph = tf.placeholder(tf.float32, ())\n",
    "tf.summary.scalar('avg_accuracy_test',  accuracy_avg, [\"TEST_STAT\"])\n",
    "tf.summary.scalar('avg_accuracy_train', accuracy_avg, [\"TRAIN_STAT\"])\n",
    "\n",
    "\n",
    "with tf.name_scope('Train'):\n",
    "    train_step = optimizer.minimize(sum_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 completed\n",
      "AVG accuracy 0.0\n",
      "Train Error {<tf.Tensor 'q_input:0' shape=(10, 40, 300) dtype=float32>: [array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [-0.007306,  0.057647,  0.024153, ...,  0.03632 , -0.041262,\n",
      "         0.029278],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [-0.005994, -0.041677,  0.002207, ..., -0.040899, -0.028839,\n",
      "         0.029405],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.052635,  0.081035, -0.077897, ..., -0.011273, -0.036543,\n",
      "        -0.032834],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.099945  , -0.033275  , -0.14107201, ..., -0.032347  ,\n",
      "         0.008426  ,  0.048992  ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       ..., \n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]]), array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.03937 ,  0.072941,  0.003212, ..., -0.008098, -0.081729,\n",
      "         0.029812],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [-0.055636,  0.05358 ,  0.051896, ..., -0.039501,  0.003882,\n",
      "         0.009636],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[-0.028302,  0.050993,  0.084835, ...,  0.067912,  0.005808,\n",
      "        -0.059526],\n",
      "       [-0.022741, -0.043927, -0.021173, ...,  0.092356, -0.092874,\n",
      "        -0.047155],\n",
      "       [ 0.005656, -0.059348, -0.019914, ...,  0.042897, -0.004617,\n",
      "        -0.063006],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.064696, -0.014162, -0.071117, ...,  0.067914, -0.043512,\n",
      "        -0.024742],\n",
      "       [ 0.013996, -0.024061, -0.018038, ...,  0.090527, -0.074751,\n",
      "         0.033452],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.092489, -0.049709,  0.020978, ..., -0.05463 , -0.054038,\n",
      "        -0.002191],\n",
      "       [ 0.06768 ,  0.013523, -0.021354, ..., -0.042497, -0.058096,\n",
      "        -0.061599],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]])], <tf.Tensor 'd_input:0' shape=(10, 160, 300) dtype=float32>: [array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.060594, -0.029158, -0.015966, ...,  0.054509, -0.029682,\n",
      "        -0.047128],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[ 0.083   ,  0.033716,  0.089272, ...,  0.036539, -0.00536 ,\n",
      "        -0.065402],\n",
      "       [-0.005994, -0.041677,  0.002207, ..., -0.040899, -0.028839,\n",
      "         0.029405],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [-0.006666, -0.059895, -0.003283, ..., -0.068496, -0.025654,\n",
      "        -0.007823],\n",
      "       [-0.033131, -0.047571,  0.023648, ..., -0.006008,  0.028234,\n",
      "         0.071998],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[-0.000507,  0.007728, -0.092586, ..., -0.037114,  0.01225 ,\n",
      "        -0.021269],\n",
      "       [-0.052418, -0.00858 , -0.022246, ...,  0.065996, -0.056685,\n",
      "        -0.009332],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.042285, -0.001217,  0.007756, ...,  0.051274, -0.026588,\n",
      "        -0.015592],\n",
      "       [ 0.04847 ,  0.027198, -0.061746, ..., -0.040448, -0.060293,\n",
      "         0.020642],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[-0.012191, -0.064369, -0.050012, ..., -0.05402 , -0.060502,\n",
      "         0.028411],\n",
      "       [-0.018404, -0.007532, -0.037935, ...,  0.009453, -0.01304 ,\n",
      "        -0.020124],\n",
      "       [-0.00014 ,  0.005718,  0.043343, ..., -0.061495, -0.090415,\n",
      "        -0.049032],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[-0.00605 ,  0.074821, -0.047479, ..., -0.014802, -0.117825,\n",
      "        -0.073102],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[-0.037434  , -0.044558  ,  0.075578  , ..., -0.035224  ,\n",
      "        -0.060729  , -0.011227  ],\n",
      "       [-0.048401  , -0.009432  ,  0.093635  , ...,  0.048824  ,\n",
      "        -0.035618  ,  0.053206  ],\n",
      "       [-0.139452  ,  0.009531  ,  0.096691  , ...,  0.13606501,\n",
      "        -0.011105  ,  0.070586  ],\n",
      "       ..., \n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        ,  0.        ]]), array([[ 0.021989, -0.030307,  0.046654, ...,  0.077866, -0.070235,\n",
      "        -0.057816],\n",
      "       [ 0.006192, -0.030751,  0.001404, ...,  0.098572, -0.05303 ,\n",
      "         0.019298],\n",
      "       [ 0.014078,  0.000224,  0.063172, ...,  0.049009, -0.079921,\n",
      "        -0.060006],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]]), array([[-0.019216, -0.04429 ,  0.011415, ..., -0.068165, -0.111305,\n",
      "        -0.018681],\n",
      "       [ 0.060715, -0.068276, -0.051474, ...,  0.053898, -0.095041,\n",
      "        -0.022172],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       ..., \n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ],\n",
      "       [ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,  0.      ]])], <tf.Tensor 'Placeholder_3:0' shape=(10,) dtype=int32>: [7, 43, 107, 106, 64, 44, 68, 16, 1, 54], <tf.Tensor 'Placeholder_4:0' shape=(10,) dtype=int32>: [9, 45, 110, 108, 68, 44, 69, 18, 1, 56], <tf.Tensor 'Placeholder_1:0' shape=(10,) dtype=int32>: [81, 125, 117, 109, 69, 76, 90, 79, 123, 116], <tf.Tensor 'Placeholder_2:0' shape=(10,) dtype=int32>: [8, 7, 9, 5, 9, 13, 21, 6, 4, 7], <tf.Tensor 'Placeholder:0' shape=<unknown> dtype=float32>: 0.5}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed\n",
      "AVG accuracy 0.05\n",
      "Epoch 2 completed\n",
      "AVG accuracy 0.0\n",
      "Epoch 3 completed\n",
      "AVG accuracy 0.04\n"
     ]
    }
   ],
   "source": [
    "#=========== Training ==================\n",
    "\n",
    "#dataset = ds.getDataset([\"./train_train_task_b.csv\"], max_sequence_length)\n",
    "#iterator = dataset.make_one_shot_iterator()\n",
    "#next_element = iterator.get_next()\n",
    "\n",
    "#dataset_validation = ds.getDataset([\"./test_dataset_160.csv\"], max_sequence_length)\n",
    "#iterator_valid = dataset_validation.make_one_shot_iterator()\n",
    "#next_element_valid = iterator_valid.get_next()\n",
    "\n",
    "summary_op_train = tf.summary.merge_all(\"TRAIN_STAT\")\n",
    "summary_op_test = tf.summary.merge_all(\"TEST_STAT\")\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "DATASET_LENGTH = 5\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    h_param_str = utils.make_h_param_string(FLAGS.learning_rate, FLAGS.lstm_size, max_sequence_length, FLAGS.maxout_pooling_size)\n",
    "    writer = tf.summary.FileWriter(FLAGS.log_path + \"/4-\" + h_param_str, sess.graph)\n",
    "    with open('test_dataset_160.csv') as file_test:\n",
    "        for epoch_ in range(200 or max_epoch):\n",
    "            step_ = 0;\n",
    "            with open('train_dataset_160.csv') as file_train:\n",
    "                while True:\n",
    "                    feed_dict = tr.processLineBatch(file_train, batch_size, \n",
    "                                                    max_sequence_length, max_question_length, \n",
    "                                                    question_ph, document_ph, dropout_rate_ph,\n",
    "                                                    doc_len_ph, que_len_ph, start_true, end_true,\n",
    "                                                    0.5)\n",
    "                    if feed_dict is None: break\n",
    "                    tr.trainStep(sess, \n",
    "                                 feed_dict, \n",
    "                                 writer, \n",
    "                                 train_step, sum_loss, accuracy_avg, summary_op, summary_op_train, \n",
    "                                 epoch_ * DATASET_LENGTH + step_, profiling=False)\n",
    "                    step_+= 1\n",
    "                    if (step_ >= DATASET_LENGTH): break;\n",
    "                        \n",
    "            print('Epoch', epoch_, 'completed')\n",
    "            test_params = tr.processLineBatch(file_test, batch_size, max_sequence_length, max_question_length, \n",
    "                                              question_ph, document_ph, dropout_rate_ph,\n",
    "                                              doc_len_ph, que_len_ph, start_true, end_true,\n",
    "                                              1)\n",
    "            tr.accuracyTest(sess, test_params, writer, \n",
    "                            accuracy_avg, summary_op, summary_op_test, pr_start_idx, pr_end_idx, epoch_)\n",
    "        print('End')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
