{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#import maxout\n",
    "import highway_maxout as hmn\n",
    "import utils\n",
    "import encoder as enc\n",
    "import dataset as ds\n",
    "import train as tr\n",
    "import decoder as dec\n",
    "import time\n",
    "from itertools import islice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#======= FLAGS ==========\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "tf.app.flags.DEFINE_integer('maxout_layer_size', 200, 'Maxout layer size')\n",
    "tf.app.flags.DEFINE_integer('max_sequence_length', 160, 'Max length of context')\n",
    "tf.app.flags.DEFINE_integer('max_question_length', 40, 'Max question tokens length')\n",
    "tf.app.flags.DEFINE_float('learning_rate', 0.001, 'Learning Rate')\n",
    "tf.app.flags.DEFINE_integer('maxout_pooling_size', 8, 'Maxout pooling size')\n",
    "tf.app.flags.DEFINE_integer('lstm_size', 200, 'LSTM cell internal size')\n",
    "tf.app.flags.DEFINE_string('log_path', '/tmp/working/logs', 'logs location')\n",
    "tf.app.flags.DEFINE_integer('acc_batch_size', 10, 'How many examples to use to calculate accuracy')\n",
    "tf.app.flags.DEFINE_integer('train_batch_size', 10, 'Train Batch Size')\n",
    "tf.app.flags.DEFINE_integer('max_decoder_iterations', 4, 'Decoder Iterations')\n",
    "tf.app.flags.DEFINE_integer('max_epoch', 200, 'Max Train Epoch Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove all variables\n",
    "#tf.reset_default_graph();\n",
    "\n",
    "lstm_size = FLAGS.lstm_size\n",
    "acc_batch_size = FLAGS.acc_batch_size\n",
    "word_vector_size = 300\n",
    "maxout_pooling_size = FLAGS.maxout_pooling_size\n",
    "max_decoder_iterations = FLAGS.max_decoder_iterations\n",
    "maxout_layer_size = FLAGS.maxout_layer_size;\n",
    "max_epoch = FLAGS.max_epoch;\n",
    "max_sequence_length = FLAGS.max_sequence_length;\n",
    "max_question_length = FLAGS.max_question_length\n",
    "batch_size = FLAGS.train_batch_size\n",
    "\n",
    "\n",
    "dropout_rate_ph = tf.placeholder(tf.float32)\n",
    "question_ph = tf.placeholder(tf.float32, [batch_size, max_question_length, word_vector_size], name=\"q_input\")\n",
    "document_ph = tf.placeholder(tf.float32, [batch_size, max_sequence_length, word_vector_size], name=\"d_input\")\n",
    "doc_len_ph = tf.placeholder(tf.int32, [batch_size])\n",
    "que_len_ph = tf.placeholder(tf.int32, [batch_size])\n",
    "document_size = doc_len_ph\n",
    "question_size = que_len_ph\n",
    "\n",
    "with tf.name_scope('ENCODER'):\n",
    "    # LSTM cell initialization\n",
    "    lstm = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm = tf.nn.rnn_cell.DropoutWrapper(cell=lstm, output_keep_prob=dropout_rate_ph)\n",
    "\n",
    "\n",
    "# LSTM cells for Bi-LSTM for COATINATION ENCODER\n",
    "with tf.name_scope('COATTENTION_ENCODER'):\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_fw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_fw, output_keep_prob=dropout_rate_ph)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.LSTMCell(lstm_size)\n",
    "    lstm_cenc_bw = tf.nn.rnn_cell.DropoutWrapper(cell=lstm_cenc_bw, output_keep_prob=dropout_rate_ph)\n",
    "\n",
    "# create lstm cell for DYNAMIC POINTING DECODER\n",
    "lstm_dec = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "# get lstm initial state of zeroes\n",
    "#lstm_dec_state = lstm_dec.zero_state(1, tf.float32)\n",
    "start_pos = 0; # ?generate random between (0, document_size-1)\n",
    "end_pos = 0;   # ?generate random between (0, document_size-1)\n",
    "\n",
    "# create sentinel vector variable for both encodings \n",
    "#with tf.variable_scope(\"scope1\") as scope:\n",
    "sentinel_q = tf.get_variable(\"sentinel_q\", [ 1, lstm_size ], initializer = tf.random_normal_initializer())\n",
    "sentinel_d = tf.get_variable(\"sentinel_d\", [ 1, lstm_size ], initializer = tf.random_normal_initializer()) \n",
    "\n",
    "tf.summary.histogram('sentinel_q', sentinel_q)\n",
    "tf.summary.histogram('sentinel_q_max', tf.reduce_max(sentinel_q))\n",
    "tf.summary.histogram('sentinel_d', sentinel_d)\n",
    "tf.summary.histogram('sentinel_d_max', tf.reduce_max(sentinel_d))\n",
    "\n",
    "# optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=FLAGS.learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"COATTENTION_ENCODER_1/Slice_2:0\", shape=(10, 160, 400), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# (batch, D, 2L)\n",
    "U = enc.encoderBatch(\n",
    "    document_ph, question_ph, \n",
    "    document_size, question_size, \n",
    "    lstm, lstm_cenc_fw, lstm_cenc_bw, \n",
    "    sentinel_d, sentinel_q, \n",
    "    FLAGS)\n",
    "print(U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================== DYNAMIC POINTING DECODER =============\n",
    "\n",
    "sum_start_scores, sum_end_scores = dec.decoderBatch(U, lstm_dec, dropout_rate_ph, FLAGS)\n",
    "\n",
    "start_true = tf.placeholder(tf.int32, [batch_size]);\n",
    "end_true   = tf.placeholder(tf.int32, [batch_size]);\n",
    "    \n",
    "#sum_start_scores = tf.Print(sum_start_scores, [start_end_true, sum_start_scores], 'sum_start_scores: ')\n",
    "#sum_end_scores = tf.Print(sum_end_scores, [start_end_true, sum_end_scores], 'sum_start_scores: ')\n",
    "    \n",
    "    \n",
    "# loss and train step\n",
    "onehot_labels_start = tf.one_hot(start_true, max_sequence_length)\n",
    "onehot_labels_end   = tf.one_hot(end_true, max_sequence_length)\n",
    "#print(\"sum_start_scores\", sum_start_scores)\n",
    "with tf.name_scope('Loss'):\n",
    "    loss_start = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels = onehot_labels_start,\n",
    "        logits = sum_start_scores)\n",
    "    loss_start = tf.reduce_mean(loss_start)\n",
    "    loss_end = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels = onehot_labels_end,\n",
    "        logits = sum_end_scores)\n",
    "    loss_end = tf.reduce_mean(loss_end)\n",
    "    sum_loss = loss_start + loss_end\n",
    "\n",
    "\n",
    "tf.summary.histogram('sum_start_scores', sum_start_scores)\n",
    "tf.summary.histogram('sum_end_scores', sum_end_scores)\n",
    "tf.summary.scalar('loss_test', sum_loss, [\"TEST_STAT\"])\n",
    "tf.summary.scalar('loss_train', sum_loss, [\"TRAIN_STAT\"])\n",
    "    \n",
    "with tf.name_scope('Accuracy'):\n",
    "    with tf.name_scope('Prediction'):\n",
    "        pr_start_idx = tf.to_int32(tf.argmax(sum_start_scores, 1))\n",
    "        pr_end_idx = tf.to_int32(tf.argmax(sum_end_scores, 1))\n",
    "         \n",
    "    with tf.name_scope('Accuracy'):\n",
    "        accuracy_avg = tf.py_func(utils.f1_score_int_avg, [pr_start_idx, pr_end_idx, start_true, end_true], tf.float64)\n",
    "        #accuracy_avg = tf.Print(accuracy_avg, [[start_true, end_true], [pr_start_idx, pr_end_idx], accuracy_avg], 'True and Predicted: ')\n",
    "\n",
    "\n",
    "#avg_accuracy_ph = tf.placeholder(tf.float32, ())\n",
    "tf.summary.scalar('avg_accuracy_test',  accuracy_avg, [\"TEST_STAT\"])\n",
    "tf.summary.scalar('avg_accuracy_train', accuracy_avg, [\"TRAIN_STAT\"])\n",
    "\n",
    "\n",
    "with tf.name_scope('Train'):\n",
    "    train_step = optimizer.minimize(sum_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train step  4.145089864730835 seconds ---\n",
      "--- Train step  4.002202749252319 seconds ---\n",
      "--- Train step  3.8989531993865967 seconds ---\n",
      "--- Train step  3.874638319015503 seconds ---\n",
      "--- Train step  3.918964385986328 seconds ---\n",
      "Epoch 0 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.116612434387207 seconds ---\n",
      "--- Train step  4.255705118179321 seconds ---\n",
      "--- Train step  4.6843976974487305 seconds ---\n",
      "--- Train step  4.6095170974731445 seconds ---\n",
      "--- Train step  3.9668636322021484 seconds ---\n",
      "Epoch 1 completed\n",
      "AVG accuracy 0.0285714285714\n",
      "--- Train step  3.8603436946868896 seconds ---\n",
      "--- Train step  3.8816704750061035 seconds ---\n",
      "--- Train step  4.154948472976685 seconds ---\n",
      "--- Train step  4.178308963775635 seconds ---\n",
      "--- Train step  4.086636543273926 seconds ---\n",
      "Epoch 2 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.109619140625 seconds ---\n",
      "--- Train step  3.8694651126861572 seconds ---\n",
      "--- Train step  3.914935827255249 seconds ---\n",
      "--- Train step  3.904529094696045 seconds ---\n",
      "--- Train step  3.890857696533203 seconds ---\n",
      "Epoch 3 completed\n",
      "AVG accuracy 0.04\n",
      "--- Train step  3.8773064613342285 seconds ---\n",
      "--- Train step  3.898109197616577 seconds ---\n",
      "--- Train step  5.0232017040252686 seconds ---\n",
      "--- Train step  3.855112314224243 seconds ---\n",
      "--- Train step  3.924975633621216 seconds ---\n",
      "Epoch 4 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  3.8535573482513428 seconds ---\n",
      "--- Train step  3.8770759105682373 seconds ---\n",
      "--- Train step  4.059559106826782 seconds ---\n",
      "--- Train step  3.8947250843048096 seconds ---\n",
      "--- Train step  3.902143716812134 seconds ---\n",
      "Epoch 5 completed\n",
      "AVG accuracy 0.0451948051948\n",
      "--- Train step  3.8365843296051025 seconds ---\n",
      "--- Train step  3.8597896099090576 seconds ---\n",
      "--- Train step  3.8914201259613037 seconds ---\n",
      "--- Train step  4.346857309341431 seconds ---\n",
      "--- Train step  3.83901309967041 seconds ---\n",
      "Epoch 6 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  3.8726861476898193 seconds ---\n",
      "--- Train step  3.8642520904541016 seconds ---\n",
      "--- Train step  3.886337995529175 seconds ---\n",
      "--- Train step  3.8767735958099365 seconds ---\n",
      "--- Train step  4.337569713592529 seconds ---\n",
      "Epoch 7 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.046694993972778 seconds ---\n",
      "--- Train step  4.410678148269653 seconds ---\n",
      "--- Train step  4.324992895126343 seconds ---\n",
      "--- Train step  3.8518667221069336 seconds ---\n",
      "--- Train step  4.1949708461761475 seconds ---\n",
      "Epoch 8 completed\n",
      "AVG accuracy 0.0666666666667\n",
      "--- Train step  3.943392276763916 seconds ---\n",
      "--- Train step  5.093942165374756 seconds ---\n",
      "--- Train step  4.241143703460693 seconds ---\n",
      "--- Train step  4.387031316757202 seconds ---\n",
      "--- Train step  4.86331582069397 seconds ---\n",
      "Epoch 9 completed\n",
      "AVG accuracy 0.1\n",
      "--- Train step  4.234041929244995 seconds ---\n",
      "--- Train step  5.0253684520721436 seconds ---\n",
      "--- Train step  4.312392950057983 seconds ---\n",
      "--- Train step  4.098113775253296 seconds ---\n",
      "--- Train step  4.096396446228027 seconds ---\n",
      "Epoch 10 completed\n",
      "AVG accuracy 0.0125\n",
      "--- Train step  4.1046435832977295 seconds ---\n",
      "--- Train step  3.8758158683776855 seconds ---\n",
      "--- Train step  4.133667230606079 seconds ---\n",
      "--- Train step  4.488084077835083 seconds ---\n",
      "--- Train step  4.620615005493164 seconds ---\n",
      "Epoch 11 completed\n",
      "AVG accuracy 0.05\n",
      "--- Train step  4.808015584945679 seconds ---\n",
      "--- Train step  3.952369451522827 seconds ---\n",
      "--- Train step  3.9333112239837646 seconds ---\n",
      "--- Train step  3.908517837524414 seconds ---\n",
      "--- Train step  3.872978687286377 seconds ---\n",
      "Epoch 12 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.25438666343689 seconds ---\n",
      "--- Train step  3.97757887840271 seconds ---\n",
      "--- Train step  4.294662714004517 seconds ---\n",
      "--- Train step  4.171138525009155 seconds ---\n",
      "--- Train step  4.31790566444397 seconds ---\n",
      "Epoch 13 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.229080438613892 seconds ---\n",
      "--- Train step  4.011038780212402 seconds ---\n",
      "--- Train step  3.9384450912475586 seconds ---\n",
      "--- Train step  4.141611099243164 seconds ---\n",
      "--- Train step  4.243408441543579 seconds ---\n",
      "Epoch 14 completed\n",
      "AVG accuracy 0.0666666666667\n",
      "--- Train step  4.422616720199585 seconds ---\n",
      "--- Train step  3.9566457271575928 seconds ---\n",
      "--- Train step  4.200377941131592 seconds ---\n",
      "--- Train step  3.888679027557373 seconds ---\n",
      "--- Train step  3.997408628463745 seconds ---\n",
      "Epoch 15 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.0194690227508545 seconds ---\n",
      "--- Train step  4.106116771697998 seconds ---\n",
      "--- Train step  4.8262269496917725 seconds ---\n",
      "--- Train step  4.4874796867370605 seconds ---\n",
      "--- Train step  4.07089376449585 seconds ---\n",
      "Epoch 16 completed\n",
      "AVG accuracy 0.0584507042254\n",
      "--- Train step  3.9132602214813232 seconds ---\n",
      "--- Train step  3.858273506164551 seconds ---\n",
      "--- Train step  3.9002339839935303 seconds ---\n",
      "--- Train step  3.929044008255005 seconds ---\n",
      "--- Train step  3.855807065963745 seconds ---\n",
      "Epoch 17 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  3.8731298446655273 seconds ---\n",
      "--- Train step  3.9119884967803955 seconds ---\n",
      "--- Train step  3.9032530784606934 seconds ---\n",
      "--- Train step  3.869938611984253 seconds ---\n",
      "--- Train step  3.7539327144622803 seconds ---\n",
      "Epoch 18 completed\n",
      "AVG accuracy 0.0147058823529\n",
      "--- Train step  3.6849803924560547 seconds ---\n",
      "--- Train step  3.6791186332702637 seconds ---\n",
      "--- Train step  3.905672788619995 seconds ---\n",
      "--- Train step  3.8296844959259033 seconds ---\n",
      "--- Train step  4.153847932815552 seconds ---\n",
      "Epoch 19 completed\n",
      "AVG accuracy 0.04\n",
      "--- Train step  4.246509075164795 seconds ---\n",
      "--- Train step  4.122180938720703 seconds ---\n",
      "--- Train step  4.403040885925293 seconds ---\n",
      "--- Train step  3.9658610820770264 seconds ---\n",
      "--- Train step  3.9798736572265625 seconds ---\n",
      "Epoch 20 completed\n",
      "AVG accuracy 0.0251282051282\n",
      "--- Train step  3.9851186275482178 seconds ---\n",
      "--- Train step  4.156382083892822 seconds ---\n",
      "--- Train step  4.202881574630737 seconds ---\n",
      "--- Train step  4.158161878585815 seconds ---\n",
      "--- Train step  4.2192113399505615 seconds ---\n",
      "Epoch 21 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.382081985473633 seconds ---\n",
      "--- Train step  4.17557954788208 seconds ---\n",
      "--- Train step  4.4114954471588135 seconds ---\n",
      "--- Train step  4.731184720993042 seconds ---\n",
      "--- Train step  4.147363185882568 seconds ---\n",
      "Epoch 22 completed\n",
      "AVG accuracy 0.0111111111111\n",
      "--- Train step  4.176205396652222 seconds ---\n",
      "--- Train step  4.508777379989624 seconds ---\n",
      "--- Train step  4.367307424545288 seconds ---\n",
      "--- Train step  4.476963520050049 seconds ---\n",
      "--- Train step  4.153753757476807 seconds ---\n",
      "Epoch 23 completed\n",
      "AVG accuracy 0.0333333333333\n",
      "--- Train step  3.861265182495117 seconds ---\n",
      "--- Train step  4.303732633590698 seconds ---\n",
      "--- Train step  4.6235692501068115 seconds ---\n",
      "--- Train step  4.092074155807495 seconds ---\n",
      "--- Train step  4.802860498428345 seconds ---\n",
      "Epoch 24 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.320252895355225 seconds ---\n",
      "--- Train step  4.138511896133423 seconds ---\n",
      "--- Train step  4.361734390258789 seconds ---\n",
      "--- Train step  4.461347579956055 seconds ---\n",
      "--- Train step  4.0812952518463135 seconds ---\n",
      "Epoch 25 completed\n",
      "AVG accuracy 0.0043795620438\n",
      "--- Train step  4.2088823318481445 seconds ---\n",
      "--- Train step  3.988332748413086 seconds ---\n",
      "--- Train step  4.016088008880615 seconds ---\n",
      "--- Train step  4.358495712280273 seconds ---\n",
      "--- Train step  4.078709602355957 seconds ---\n",
      "Epoch 26 completed\n",
      "AVG accuracy 0.0694444444444\n",
      "--- Train step  4.370891809463501 seconds ---\n",
      "--- Train step  4.082059383392334 seconds ---\n",
      "--- Train step  4.2038538455963135 seconds ---\n",
      "--- Train step  4.543827295303345 seconds ---\n",
      "--- Train step  4.579397439956665 seconds ---\n",
      "Epoch 27 completed\n",
      "AVG accuracy 0.0272727272727\n",
      "--- Train step  4.239022731781006 seconds ---\n",
      "--- Train step  4.389280080795288 seconds ---\n",
      "--- Train step  4.1046812534332275 seconds ---\n",
      "--- Train step  4.362141370773315 seconds ---\n",
      "--- Train step  4.298529624938965 seconds ---\n",
      "Epoch 28 completed\n",
      "AVG accuracy 0.113333333333\n",
      "--- Train step  4.0948333740234375 seconds ---\n",
      "--- Train step  4.2843945026397705 seconds ---\n",
      "--- Train step  3.8898212909698486 seconds ---\n",
      "--- Train step  3.9206814765930176 seconds ---\n",
      "--- Train step  4.066350698471069 seconds ---\n",
      "Epoch 29 completed\n",
      "AVG accuracy 0.0937142857143\n",
      "--- Train step  3.9408419132232666 seconds ---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Train step  3.9248976707458496 seconds ---\n",
      "--- Train step  4.165650129318237 seconds ---\n",
      "--- Train step  4.030949592590332 seconds ---\n",
      "--- Train step  3.9953320026397705 seconds ---\n",
      "Epoch 30 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.524253606796265 seconds ---\n",
      "--- Train step  4.411677122116089 seconds ---\n",
      "--- Train step  4.402179956436157 seconds ---\n",
      "--- Train step  4.2806384563446045 seconds ---\n",
      "--- Train step  4.356121301651001 seconds ---\n",
      "Epoch 31 completed\n",
      "AVG accuracy 0.075\n",
      "--- Train step  4.27769660949707 seconds ---\n",
      "--- Train step  4.2625415325164795 seconds ---\n",
      "--- Train step  4.367735862731934 seconds ---\n",
      "--- Train step  4.45237135887146 seconds ---\n",
      "--- Train step  4.0404603481292725 seconds ---\n",
      "Epoch 32 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.028284549713135 seconds ---\n",
      "--- Train step  4.215728282928467 seconds ---\n",
      "--- Train step  3.9904537200927734 seconds ---\n",
      "--- Train step  4.196514844894409 seconds ---\n",
      "--- Train step  4.217299461364746 seconds ---\n",
      "Epoch 33 completed\n",
      "AVG accuracy 0.0488721804511\n",
      "--- Train step  4.418425559997559 seconds ---\n",
      "--- Train step  4.679155349731445 seconds ---\n",
      "--- Train step  4.413523197174072 seconds ---\n",
      "--- Train step  4.307243824005127 seconds ---\n",
      "--- Train step  4.135231971740723 seconds ---\n",
      "Epoch 34 completed\n",
      "AVG accuracy 0.0863636363636\n",
      "--- Train step  4.312220335006714 seconds ---\n",
      "--- Train step  4.13689398765564 seconds ---\n",
      "--- Train step  4.320312023162842 seconds ---\n",
      "--- Train step  4.110858201980591 seconds ---\n",
      "--- Train step  4.14762544631958 seconds ---\n",
      "Epoch 35 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.330883979797363 seconds ---\n",
      "--- Train step  4.063340663909912 seconds ---\n",
      "--- Train step  3.985154151916504 seconds ---\n",
      "--- Train step  4.185537099838257 seconds ---\n",
      "--- Train step  4.181421279907227 seconds ---\n",
      "Epoch 36 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.440969228744507 seconds ---\n",
      "--- Train step  4.17152214050293 seconds ---\n",
      "--- Train step  4.047619342803955 seconds ---\n",
      "--- Train step  3.9971749782562256 seconds ---\n",
      "--- Train step  4.176102638244629 seconds ---\n",
      "Epoch 37 completed\n",
      "AVG accuracy 0.04\n",
      "--- Train step  4.413819789886475 seconds ---\n",
      "--- Train step  4.750531911849976 seconds ---\n",
      "--- Train step  4.079944133758545 seconds ---\n",
      "--- Train step  4.737673044204712 seconds ---\n",
      "--- Train step  4.488435745239258 seconds ---\n",
      "Epoch 38 completed\n",
      "AVG accuracy 0.04\n",
      "--- Train step  4.461928844451904 seconds ---\n",
      "--- Train step  4.2688422203063965 seconds ---\n",
      "--- Train step  4.457277297973633 seconds ---\n",
      "--- Train step  4.496256589889526 seconds ---\n",
      "--- Train step  4.510432243347168 seconds ---\n",
      "Epoch 39 completed\n",
      "AVG accuracy 0.0\n",
      "--- Train step  4.699188709259033 seconds ---\n",
      "--- Train step  4.501874923706055 seconds ---\n",
      "--- Train step  4.391270875930786 seconds ---\n"
     ]
    }
   ],
   "source": [
    "#=========== Training ==================\n",
    "\n",
    "#dataset = ds.getDataset([\"./train_train_task_b.csv\"], max_sequence_length)\n",
    "#iterator = dataset.make_one_shot_iterator()\n",
    "#next_element = iterator.get_next()\n",
    "\n",
    "#dataset_validation = ds.getDataset([\"./test_dataset_160.csv\"], max_sequence_length)\n",
    "#iterator_valid = dataset_validation.make_one_shot_iterator()\n",
    "#next_element_valid = iterator_valid.get_next()\n",
    "\n",
    "summary_op_train = tf.summary.merge_all(\"TRAIN_STAT\")\n",
    "summary_op_test = tf.summary.merge_all(\"TEST_STAT\")\n",
    "summary_op = tf.summary.merge_all()\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "DATASET_LENGTH = 5\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    h_param_str = utils.make_h_param_string(FLAGS.learning_rate, FLAGS.lstm_size, max_sequence_length, FLAGS.maxout_pooling_size)\n",
    "    writer = tf.summary.FileWriter(FLAGS.log_path + \"/4-\" + h_param_str, sess.graph)\n",
    "    with open('test_dataset_160.csv') as file_test:\n",
    "        for epoch_ in range(200 or max_epoch):\n",
    "            step_ = 0;\n",
    "            with open('train_dataset_160.csv') as file_train:\n",
    "                while True:\n",
    "                    feed_dict = tr.processLineBatch(file_train, batch_size, \n",
    "                                                    max_sequence_length, max_question_length, \n",
    "                                                    question_ph, document_ph, dropout_rate_ph,\n",
    "                                                    doc_len_ph, que_len_ph, start_true, end_true,\n",
    "                                                    0.5)\n",
    "                    if feed_dict is None: break\n",
    "                    tr.trainStep(sess, \n",
    "                                 feed_dict, \n",
    "                                 writer, \n",
    "                                 train_step, sum_loss, accuracy_avg, summary_op, summary_op_train, \n",
    "                                 epoch_ * DATASET_LENGTH + step_, profiling=False)\n",
    "                    step_+= 1\n",
    "                    if (step_ >= DATASET_LENGTH): break;\n",
    "                        \n",
    "            print('Epoch', epoch_, 'completed')\n",
    "            test_params = tr.processLineBatch(file_test, batch_size, max_sequence_length, max_question_length, \n",
    "                                              question_ph, document_ph, dropout_rate_ph,\n",
    "                                              doc_len_ph, que_len_ph, start_true, end_true,\n",
    "                                              1)\n",
    "            tr.accuracyTest(sess, test_params, writer, \n",
    "                            accuracy_avg, summary_op, summary_op_test, pr_start_idx, pr_end_idx, epoch_)\n",
    "        print('End')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
